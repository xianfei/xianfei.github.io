[{"content":"翻译自：https://www.semianalysis.com/p/gpt-4-architecture-infrastructure\n原文标题：GPT-4 Architecture, Infrastructure, Training Dataset, Costs,Vision, MoE\n原文副标题：Demystifying GPT-4: The engineering tradeoffs that led OpenAI to their architecture.\n前言 \u0026amp; 综述 OpenAI 保持 GPT-4 架构的神秘感及闭源并不是因为怕人们担心对人类存在一些生存风险，而是因为他们构建的东西是可复制的。 事实上，我们预计 Google、Meta、Anthropic、Inflection、Character、腾讯、字节跳动、百度等在短期内都将拥有与 GPT-4 一样强大的模型。\n不要误会我们的意思，OpenAI 拥有令人惊叹的工程，他们构建的东西令人难以置信，但他们得出的解决方案并不神奇。 这是一个优雅的解决方案，具有许多复杂的权衡。 做大只是战斗的一部分。 OpenAI 最持久的护城河是他们在全球范围内被广泛使用（拥有大量的数据）、领先的工程人才，并且可以通过未来的模型继续领先于其他人。\n我们从许多来源收集了大量有关 GPT-4 的信息，今天我们想分享一下。 这包括模型架构、训练基础设施、推理基础设施、参数计数、训练数据集组成、token数、层数、并行策略、多模态视觉适配、不同工程权衡背后的思维过程、独特的实施技术以及它们如何缓解矩形模型在推理上的巨大瓶颈。\n研究 GPT-4 最有趣的方面是，理解他们为什么做出某些架构上的决定。\n此外，我们将大致猜测 A100 上 GPT-4 的训练和推理成本，以及如何在下一代模型架构中与 H100 计算卡的情况下进行进一步的扩展。\n首先，从 GPT-3 到 GPT-4，OpenAI 希望扩展 100 倍，但成本是很大的问题。 Dense Transformers 模型很难进一步扩大参数量1。 Dense Transformers 是 OpenAI GPT-3、Google PaLM、Meta LLAMA、TII Falcon、MosaicML MPT 等使用的模型架构。 我们可以轻松说出 50 家使用相同架构来训练LLMs（大语言模型）的公司。 这是一个很好的方法，但它在扩展方面存在缺陷。\n从训练成本的角度来看，可以参阅我们在 GPT-4 之前关于即将推出的密集（同前文中的Dense）模型The AI Brick Wall的训练成本讨论1。 在那里，我们揭示了 OpenAI 在 GPT-4 架构方面所做的 high-level 工作以及各种现有模型的训练成本。\n但是在过去的 6 个月里，我们意识到训练成本并不是一个决定性因素（irrelevant）。\n当然，从表面上看，花费数千万甚至数亿美元的计算时间来训练模型似乎很疯狂，但这对于这些公司来说是微不足道的。 它实际上是一个资本支出（Capex line）项目，规模扩大可以持续带来更好的结果。 唯一的限制因素是将计算扩展到一个时间尺度，以便人类可以得到反馈并修改架构。\n未来几年，谷歌、Meta、OpenAI/微软等多家公司将在价值超过千亿美元的超级计算机上训练模型。 Meta 每年在“元宇宙（Metaverse）”上烧了超过 160 亿美元，Google 每年在各种永远不会实现成果的项目上浪费 100 亿美元。 亚马逊在 Alexa 上损失了超过 50 亿美元。 加密货币在毫无价值的情况下浪费了超过 1000 亿美元\n这些公司和其他组织可以而且将会花费超过一千亿美元来创建可以训练单个大规模模型的超级计算机。 然后可以通过多种方式将这些大型模型产品化。这项工作将在多个国家和公司重复进行。 这是新的军备竞赛。 以前的浪费与现在的区别在于，人工智能可以在取代部分人类的工作上短期内带来有形的价值。\n扩展人工智能（真正的人工智能砖墙）的更重要问题是推理。 目标是将训练计算与推理计算分离。 这就是为什么训练 Chinchilla 对于任何将要部署的模型来说都是最佳的。 这就是为什么要进行稀疏模型架构； 并不是每个参数在推理过程中都会被使用到。\n真正的棘手的问题这些模型的用户使用的成本太高。推理成本是训练成本的数倍。这就是OpenAI在模型架构和基础设施方面的创新目标。\n大型模型的推理是一个多变量问题，在这个问题中，密集模型的模型大小会成为致命的问题。我们已经在这里2详细讨论了关于边缘计算的问题，但对于数据中心来说，问题是非常相似的。简要概述就是，设备永远无法拥有足够的内存带宽来让大型语言模型达到一定程度的吞吐量。即使它们拥有足够的带宽，边缘计算上硬件计算资源的利用率也会非常低。\n在数据中心和云端，利用率是至关重要的。Nvidia因软件优越性而受到赞誉的一半原因是，在GPU的几代生命周期中，Nvidia不断更新底层软件，通过更智能地在芯片内、芯片之间以及内存之间移动数据，从而提高FLOPS利用率。\n在大多数当前的应用场景中，LLM推理的作用是作为实时助手，这意味着它必须实现足够高的吞吐量，以便用户实际使用。人类平均每分钟阅读速度约为250个单词，但有些人的阅读速度高达每分钟1000个单词。这意味着你需要每秒输出至少8.33个 token （tokens），但每秒输出33.33个 token 才能覆盖所有极端情况。\n由于内存带宽要求，即使在最新的Nvidia H100 GPU服务器上，一个拥有万亿参数的密集型模型也无法实现这种吞吐量。每生成一个 token ，都需要将每个参数从内存加载到芯片上。然后将生成的 token 输入到提示中，并生成下一个 token 。此外，还需要额外的带宽来为注意力机制中的KV缓存进行流式传输。\n图注：该图表假设由于无法融合每个操作、注意力机制所需的内存带宽和硬件开销等低效问题，等同于参数读取。实际上，即使使用像英伟达的FasterTransformer库这样的“优化”库，总开销甚至更大。\n上图展示了为了以足够高的吞吐量为单个用户提供LLM推断服务所需的内存带宽。它表明，即使是8个 H100 也无法在每秒33.33个 token 的速度下为1万亿参数的密集模型提供服务。此外，在每秒20个 token 的速度下，8xH100的FLOPS利用率仍然低于5%，导致推断成本极高。实际上，对于目前的8路张量并行H100系统，推断约束在约3000亿前馈参数左右。\n然而，OpenAI使用A100实现了人类阅读速度，并使用了超过1万亿参数的模型，而且他们以每1000个 token 仅0.06美元的低价广泛提供。这是因为它是稀疏的，即并非每个参数都被使用。\n关于GPT-4模型架构、训练基础设施、推断基础设施、参数数量、训练数据集组成、 token 数量、层数、并行策略、多模态视觉编码器、不同工程权衡背后的思考过程、独特实施技术以及如何减轻与巨型模型推断相关的一些最大瓶颈的问题，我们不再拖泥带水，直接进入主题。\n模型架构 Model Architecture GPT-4的大小是GPT-3的10倍以上。我们认为它在120个层次上拥有约1.8万亿个参数，而GPT-3的参数约为1750亿个。\nOpenAI通过使用专家混合（MoE, mixture of experts）模型来保持成本合理。如果您不熟悉MoE，请阅读我们6个月前关于广义GPT-4架构和训练成本的文章。\n此外，OpenAI在其模型中使用了16个专家模型，每个专家模型的MLP参数约为1110亿个。其中有2个专家模型被路由到每个前向传递中。\n虽然文献中谈到了很多高级路由算法，用于选择将每个 token 路由到哪个专家，但OpenAI的路由算法据称对于当前的GPT-4模型来说相当简单。此外，注意力（此处指Transformer的Attention）约有550亿个共享的参数。\n每个前向传递推断（生成1个 token ）仅使用约2800亿个参数和约560 TFLOP。这与纯密集模型每个前向传递所需的约1.8万亿个参数和约3700 TFLOP形成鲜明对比。\n数据集构成 Dataset Composition OpenAI 在大约 13 万亿个 tokens 的数据集上训练了 GPT-4。其中 CommonCrawl RefinedWeb 包含大约 5 万亿个高质量 tokens。作为参考，Deepmind 的 Chinchilla 和 Google 的 PaLM 模型分别在大约 1.4 万亿 tokens 和大约 0.78 万亿 tokens 上进行了训练。甚至据称 PaLM 2 也在大约 5 万亿 tokens 上进行了训练。\nCommonCrawl 是一个非营利组织，它定期从互联网上抓取和存储网页数据。它提供一个包含数十亿个网页的大型公共数据集，这些网页来自于全球各地的多种语言。这个数据集对于研究人员、开发者和企业来说非常有价值，因为它可以用于训练机器学习模型，例如自然语言处理（NLP）任务，以及进行其他大数据分析。在本文中，CommonCrawl 用于提供大量高质量 tokens，以便在训练 GPT-4 时使用。\n这个数据集并非 13 万亿个独特的 tokens。相反，由于缺乏高质量 tokens，数据集包含了多个时期。文本数据有 2 个时期，代码数据有 4 个时期。有趣的是，这远远低于 Chinchilla 的最优值，表明需要在双倍的 token 数量上训练模型。这表明网络上缺乏易于获取的 tokens。实际上存在着 1000 倍以上的高质量文本 tokens，甚至还有更多的音频和视觉 tokens，但获取它们并不像网络抓取那样简单。\n还有来自 ScaleAI 和内部的数百万行指令微调数据。不幸的是，我们没有找到关于他们 RLHF 数据的更多信息。预训练阶段有 8k 的上下文长度（seqlen）。GPT-4 的 32k seqlen 版本是基于预训练后的 8k 进行微调的。\n在集群上，批量大小在数天内逐渐增加，但最后，OpenAI 使用了一个批量大小为 6000 万！当然，由于并非每个专家都能看到所有 tokens，这只是每位专家的 750 万 tokens 的“仅仅”一个批次大小。\n并行策略 Parallelism Strategies 能够利用所有A100 GPU的并行策略至关重要。他们利用了8路张量并行，因为这是NVLink的极限。除此之外，我们听说他们正在使用15路流水线并行。从理论上讲，考虑到数据通信与计算时间，这是过多的流水线，但如果他们受到内存容量的限制，那么这是有道理的。\n在纯粹的流水线+张量并行的情况下，每个GPU在FP16下仅参数就需要约30GB。一旦加上KV缓存和开销，如果OpenAI的大部分GPU都是40GB A100，那么从理论上讲这是有道理的。他们可能使用了ZeRo阶段1。他们可能使用了块级FSDP（全分布式状态并行）或混合共享数据并行。\nZeRo（Zero Redundancy Optimizer，零冗余优化器）是一种用于降低深度学习训练中内存需求的技术。ZeRo Stage 1 是这个优化策略的第一阶段。在这个阶段，优化器状态和梯度被分布式存储在多个 GPU 或设备上，从而减少了每个设备的内存占用。这使得在有限的硬件资源下训练更大的模型成为可能。\nFSDP（Fully Sharded Data Parallel，全分布式状态并行）和混合共享数据平行（Hybrid Shared Data Parallel）都是用于加速深度学习训练的并行计算策略，但它们的实现和关注点有所不同。\nFSDP 是一种将模型参数、优化器状态和梯度在多个设备（如 GPU）之间分片的技术。通过将这些状态分布在不同的设备上，FSDP 可以降低每个设备的内存需求，从而使得在有限的硬件资源下训练更大的模型成为可能。FSDP 还可以与其他并行策略（如模型并行和流水线并行）结合使用，以进一步提高训练速度和扩展性。\n混合共享数据平行（Hybrid Shared Data Parallel）是一种结合了数据并行和模型并行的策略。在数据并行中，每个设备都有一个完整的模型副本，并在不同的数据子集上进行训练。在模型并行中，模型被划分为多个部分，每个部分分布在不同的设备上。混合共享数据平行旨在充分利用这两种策略的优点，通过将模型参数和计算在多个设备上共享，来提高训练速度和扩展性。\n总之，FSDP 和混合共享数据平行都是为了加速深度学习训练而设计的并行计算策略，但它们关注的优化方向和实现方式有所不同。FSDP 主要关注降低内存需求，而混合共享数据平行则关注在多个设备上共享模型参数和计算。\n至于为什么他们没有使用完整模型的FSDP，可能是因为较高的通信开销。虽然OpenAI在大多数节点之间具有高速网络连接，但可能并非所有节点之间都具有这种连接。我们认为至少有一些集群的连接带宽远低于其他集群。\n我们不明白他们如何避免在如此高的流水线并行中的每个批次都有巨大的泡沫。他们可能只是承担了成本。\n训练成本 Training Cost OpenAI的GPT-4训练浮点运算次数约为2.15e25，在大约25,000个A100上进行90到100天，其MFU（机器利用率）约为32%至36%。这种极低的利用率部分原因是由于大量的故障，需要从检查点重新启动。上述提到的泡沫成本非常高。\n另一个原因是在如此多的GPU之间进行all-reduce操作非常耗费资源。这尤其是在我们怀疑集群实际上是由一堆较小的集群组成，它们之间的网络连接较弱的情况下。例如，在集群的各个部分之间有800G/1.6T的非阻塞连接，但这些部分之间只有200G/400G的连接。\n文中提到的all-reduce指的是一种并行计算中常用的通信操作，它在分布式系统中的多个节点之间进行全局归约操作。在深度学习训练过程中，all-reduce操作通常用于在多个GPU或计算节点之间同步参数更新，以便在训练大型模型时确保各个节点的模型参数保持一致。这种操作涉及在所有参与节点之间传输和聚合数据，因此在涉及大量GPU的情况下可能变得非常耗费资源和时间。\n如果他们在云中的成本约为每小时1美元的A100，那么仅此次运行的训练成本就约为6300万美元。这还不包括所有的实验、失败的训练运行以及其他成本，如数据收集、RLHF、员工等。由于这些因素，真正的成本要高得多。此外，这意味着您需要有人购买芯片/网络/数据中心，承担资本支出，并将其租给您。\n如今，预训练可以在约8,192个H100上进行约55天，每小时2美元的H100成本为2150万美元。我们相信到今年底将有9家公司拥有更多的H1003。并非所有这些公司都会将所有设备用于单次训练运行，但那些这样做的公司将拥有更大的模型。Meta到今年底将拥有超过100,000个H100，但相当数量的H100将分布在他们的数据中心进行推理。他们最大的单个集群仍将远超25k个H100。\n到今年底，许多公司将拥有足够的计算资源来训练一个GPT-4大小的模型。\n权衡 之 混合专家模型 Mixture of Expert Tradeoffs MoE是在推理过程中减少参数数量的一个很好的方法，同时仍然可以增加参数数量，这是在每个训练token中编码更多信息所必需的。这是非常必要的，因为获取足够多的高质量token非常困难。如果OpenAI真的要尝试达到Chinchilla最优，他们本来需要在2倍的token上进行训练。\n话虽如此，OpenAI做出了多种权衡。例如，MoE在推理过程中非常难以处理，因为在每个token生成过程中，并非模型的每个部分都会被利用。这意味着当其他部分被使用时，某些部分可能处于休眠状态。在为用户提供服务时，这会严重影响利用率。\n研究人员已经证明，使用64到128个专家比使用16个专家能获得更低的损失，但这仅仅是研究。选择较少专家的原因有很多。OpenAI选择16个专家的一个原因是，更多的专家很难在许多任务中泛化。更多的专家也可能更难以实现收敛。在如此大规模的训练过程中，OpenAI选择在专家数量上更为保守。\n此外，使用较少的专家还有助于降低他们的推理基础设施的需求。在转向专家混合推理架构时，存在各种困难的权衡。在讨论OpenAI面临的问题以及他们做出的选择之前，让我们先从LLMs的推理基本权衡开始。\n权衡 之 推理 Inference Tradeoffs 在开始之前，我们想顺便指出，我们与之交谈过的每一家LLM公司都认为Nvidia的FasterTransformer推理库相当糟糕，而TensorRT更是糟糕透顶。无法对Nvidia的模板进行修改意味着人们需要从头开始创建自己的解决方案。对于正在阅读本文的Nvidia的人员来说，你们需要尽快解决这个问题，以便在LLM推理方面取得优势，否则实际上将成为一个开放的工具，这样可以更容易地添加第三方硬件支持。一波巨型模型即将来临。如果在推理方面没有软件优势，而且还需要手写内核，那么AMD的MI3004和其他硬件的市场将会更大。\n在批量大小（同时服务的用户数量）维度和所使用芯片数量方面，大型语言模型推理存在3个主要权衡。\n延迟 - 模型必须在合理的延迟内做出响应。人们在聊天应用中等待输出开始流式传输之前，不希望等待太长时间。预填充（输入 tokens ）和解码（输出 tokens ）需要不同的时间来处理。\n吞吐量 - 模型必须每秒输出一定数量的 tokens 。大约每秒30个 tokens 是人类所需的。对于各种其他用例，较低和较高的吞吐量也可以接受。\n利用率 - 运行模型的硬件必须实现高利用率，否则成本会太高。虽然可以通过使用更高的延迟和更低的吞吐量将更多的用户请求组合在一起，从而实现更高的利用率，但这会增加难度\nLLM推理主要是关于平衡两个主要方面：内存带宽和计算能力。用最简化的术语来说，每个参数都需要被读取，并且与之相关的有2个FLOPs。因此，大多数芯片的比例（H100 SXM只有3TB/s的内存带宽，但有2000 TFLOP/s的FP8计算能力）对于批量大小为1的推理来说是完全不平衡的。如果只有一个用户在使用，批量大小为1，那么将每个参数流式传输到每个 token 生成所需的内存带宽将主导推理时间。计算时间几乎为零。\n要将大型语言模型有效地扩展到许多用户，批量大小必须大于1。多个用户分摊参数读取成本。例如，在批量大小为256或512的情况下，每读入一个字节的内存，就有512 FLOP/s或1024 FLOP/s。这个比例更接近H100的内存带宽与FLOPS之间的关系。这有助于实现更高的利用率，但同时也带来了更高的延迟。\n许多人认为内存容量是LLM推理的主要瓶颈，因为模型的大小可以适应多个芯片，但这是错误的。虽然大型模型需要多个芯片进行推理，较高的内存容量导致它们适应更少的芯片，但实际上，最好使用比所需容量更多的芯片，以便降低延迟，提高吞吐量，并使用更大的批量大小以实现更高的利用率。\n谷歌在他们的PaLM推理论文中展示了这些权衡。然而，值得注意的是，这是针对像PaLM这样的密集模型，而不是像GPT-4这样的稀疏模型。\n如果一个应用程序要求尽可能低的延迟，我们需要应用更多的芯片并以尽可能多的方式对模型进行划分。较低的延迟通常可以通过较小的批量大小来实现，但较小的批量大小也会导致较差的MFU(利用率)，从而导致每个 token 的总成本（以芯片秒或美元计）更高\n如果一个应用程序需要离线推理并且延迟不是一个问题，主要目标是最大化每个芯片的吞吐量（即，最小化每个 token 的总成本）。提高批量大小是最有效的方法，因为较大的批量通常会导致更好的MFU(利用率)，但是随着批量大小的增加，某些对于小批量大小不高效的划分策略变得高效。\nMFU指的是Memory Functional Unit（内存功能单元），它是计算设备（如GPU或ASIC芯片）中负责处理数据存储和访问的部分。MFU的利用率是指这些内存功能单元在处理任务时的效率。提高MFU利用率意味着计算设备能更有效地处理数据，从而提高性能。\n更多的芯片和更高的批量大小是最便宜的，因为它们提高了利用率，但这也引入了第三个变量，网络时间。将模型分割到不同芯片上的某些方法在延迟方面更有效，但会在利用率方面产生权衡。\n权重加载部分的内存时间和非注意力计算时间与模型大小成正比，与芯片数量成反比。然而，对于给定的划分布局，芯片间通信所需的时间减少得较慢（或者根本不减少），因此随着芯片数量的增加，它变得越来越重要。\n虽然我们今天只会简要讨论这个问题，但应该指出的是，随着批量大小和序列长度的增加，KV缓存的内存需求呈爆炸式增长。\n如果一个应用程序需要生成具有长注意力上下文的文本，它会显著增加推理时间。对于一个具有多头注意力的500B+模型，注意力KV缓存变得很大：对于批量大小为512且上下文长度为2048的情况，KV缓存总计为3TB，这是模型参数大小的3倍。芯片的计算核心在此期间基本上是空闲的，因为它需要从片外内存加载这个KV缓存。\n较长的序列长度对内存带宽和内存容量的影响尤为恶劣。OpenAI的16k序列长度的GPT 3.5 Turbo和32k序列长度的GPT 4由于内存限制无法使用较大的批量大小，因此价格更高。较低的批量大小导致较低的硬件利用率。此外，随着序列长度的增加，KV缓存膨胀。KV缓存无法在用户之间共享，因此需要单独读取内存，进一步限制内存带宽。稍后会有更多关于MQA（Multi-Query Attention）的内容。\nGPT-4 Inference Tradeoffs And Infrastructure 以上所说到的困难在 GPT-4 推理中都会遇到，但是专家混合（MoE）模型架构的引入会带来新的困难。每个 token 生成的前向传播可以路由到不同的专家集合。这在吞吐量、延迟和更高批量大小的利用率之间达到的权衡中产生了问题。\nOpenAI 的 GPT-4 有 16 个专家，每个前向传播有 2 个。这意味着，如果批量大小为 8，每个专家的参数读取可能仅为批量大小 1。更糟糕的是，这可能意味着 1 个专家的批量大小可能为 8，而其他专家的批量大小可能为 4、1 或 0。每一次 token 生成，路由算法都会将前向传播发送到不同的方向，导致 token 到 token 延迟以及专家批量大小的显著变化。\n推理基础设施是 OpenAI 选择更少专家数量的主要原因。如果他们选择更多的专家，内存带宽将进一步限制推理。OpenAI 在他们的推理集群上经常达到 4k+ 的批量大小，这意味着即使在专家之间进行最佳负载平衡，专家们的批量大小也只有约 500。实现这一点需要非常大量的使用。\n我们了解到，OpenAI 在 128 个 GPU 的集群上运行推理。他们在多个数据中心和地理位置拥有多个这样的集群。推理是在 8 路张量并行和 16 路流水线并行下完成的。每个包含 8 个 GPU 的节点只有约 130B 参数，即每个 GPU 在 FP16 下不到 30GB，在 FP8/int8 下不到 15GB。这使得推理可以在 40GB A100 上运行，只要 KV 缓存大小在所有批次中不会过大。\n包含各种专家的单独层不会在不同节点之间拆分，因为这会使网络流量过于不规律，而在每个 token 生成之间重新计算 KV 缓存的成本会非常高。任何未来 MoE 模型扩展和条件路由的最大困难是如何处理绕过 KV 缓存的路由。\n层的数量是 120，所以在 15 个不同的节点之间进行划分是简单的，但是因为第一个节点需要进行数据加载和嵌入，所以在推理集群的头节点上放置较少的层是有意义的。此外，还有一些关于投机解码的传言，我们稍后会讨论，但我们不确定是否相信它们。这也解释了为什么头节点需要包含更少的层。\nGPT-4 推理费用 GPT-4 Inference Cost GPT-4的成本是175B参数Davinchi模型的3倍，尽管其前馈参数仅为1.6倍。这主要是由于GPT-4所需的大型集群更多，以及实现的利用率较低。\n我们认为，对于128个A100s进行GPT-4 8k seqlen推理，每1k tokens的成本为0.0049美分；而对于128个H100s进行GPT-4 8k seqlen推理，每1k tokens的成本为0.0021美分。需要注意的是，我们假设较高的利用率，并保持批量大小较高。\n这可能是一个错误的假设，因为很明显OpenAI有时利用率非常低。我们认为OpenAI在低谷时段关闭集群，并将这些节点重新用于从检查点恢复训练较小的测试模型，尝试各种新技术。这有助于降低推理成本。如果OpenAI不这样做，他们的利用率会更低，我们的成本估计会翻一番以上。\nMulti-Query Attention MQA（Multi-Query Attention，多查询注意力）是其他所有人都在做的事情，但我们想指出OpenAI也在做。长话短说，只需要1个头，KV缓存的内存容量可以显著减少。即便如此，32k seqlen的GPT-4肯定无法在40GB的A100s上运行，而8k的最大批量大小受到限制。如果没有它，8k的最大批量大小将受到很大限制，以至于变得不经济。\n连续批量处理 Continuous batching OpenAI 实现了可变批量大小和连续批量处理。 这是为了允许一定程度的极大地优化了延迟并优化推理成本。 如果您不熟悉这个概念，AnyScale 上面的这篇文章5值得一读。\n推测性解码 Speculative Decoding 我们从一些可靠的人那里听说，OpenAI在GPT-4推理中使用了推测性解码。我们不确定是否相信这一点。在进行简单检索任务和更复杂任务时，token to token 延迟在不同时间段下会产生变化和差异6似乎表明这是可能的，但有太多的变量无法知道。以防万一，我们将在这里通过使用“加速LLM推理与分阶段推测性解码”的一些文本并进行一些修改/添加一些内容来解释它。\n通常将使用LLM分为两个阶段。首先是预填充，将提示通过模型生成KV缓存和第一个输出概率分布（可能的 token 输出）。这通常很快，因为整个提示可以并行处理。\n第二阶段是解码。从输出的概率分布中选择一个 token 并将其反馈到模型中，该模型为后续 token 生成概率分布。这一过程重复进行，直到生成所需数量的 token 。由于解码必须按顺序通过计算单元流式传输权重以生成单个 token ，因此这第二阶段的算术强度（arithmetic intensity，计算FLOP /内存带宽字节）在小批量运行时极低。因此，解码通常是自回归生成中最昂贵的部分。\n这就是为什么在OpenAI的API调用中，输入 token 比输出 token 便宜得多。推测性解码的基本思想是使用一个更小、更快的草稿模型提前解码几个 token ，然后将它们作为单个批次输入到oracle模型中。如果草稿模型对其预测是正确的——更大的模型同意——可以用单个批次解码几个 token ，从而节省大量的内存带宽，因此每个 token 的时间也节省了。\n然而，如果较大的模型拒绝了草稿模型预测的 token ，那么将丢弃批次的其余部分，并且算法自然地恢复到标准的逐 token 解码。推测性解码还可以伴随着拒绝抽样方案，从原始分布中抽样。请注意，这仅在带宽是瓶颈的小批量设置中有用。\n推测性解码用计算换带宽。推测性解码是一个有吸引力的性能工程目标的两个关键原因是：首先，它根本不会降低模型质量。其次，它提供的收益通常与其他方法正交，因为其性能来自将顺序执行转换为并行执行。\n当前的推测方法为批次预测单个序列。然而，这种方法不能很好地扩展到大批量大小或低草稿模型对齐。直观地说，两个模型对于长连续 token 序列达成一致的概率呈指数级下降，这意味着随着算术强度的增加，推测性解码的收益迅速减小。\n我们认为，如果OpenAI使用推测性解码，他们可能只使用它来处理大约4个 token 的序列。另外，关于降低GPT-4质量的整个阴谋可能仅仅是因为他们让oracle模型接受来自推测性解码模型的较低概率序列。另一个插曲是，有些人们猜测bard使用推测性解码，因为Google在将整个序列发送给用户之前等待序列生成，但我们不认为这种猜测是正确的。\n总之，推测性解码是一种在不降低模型质量的情况下提高性能的方法，它通过降低内存带宽需求来实现。然而，这种方法在某些情况下可能会受到限制，例如大批量大小或低草稿模型对齐。OpenAI可能在GPT-4中使用了推测性解码，但我们不能确定它们是否确实采用了这种方法。此外，关于GPT-4质量降低的阴谋论可能与推测性解码模型接受较低概率序列有关。尽管有关bard使用推测性解码的猜测存在，但我们不相信这种猜测是正确的。\n视觉多模态 Vision Multi-Modal GPT-4 的视觉多模态功能是相对不太令人印象深刻的部分，至少与领先的研究相比。当然，目前还没有人将这些研究商业化为多模态LLM。\n视觉编码器与文本编码器是分开的，但存在交叉注意力。我们了解到，其架构类似于Flamingo。这在GPT-4的1.8T参数之上增加了更多参数。在仅文本预训练之后，它会使用另外大约2万亿个 token 进行微调。\n在视觉模型方面，OpenAI希望从头开始训练，但成熟度不够，因此他们希望通过从文本开始来降低风险。\n他们将训练的下一个模型，GPT-5，据称将从头开始进行视觉训练，并能够自己生成图像。此外，它还将能够处理音频。\n这种视觉功能的主要目的之一是用于能够阅读网页并转录图像和视频内容的自主代理。他们训练的一些数据是联合数据（渲染的LaTeX/文本）、网页截图、YouTube 视频中的部分帧及运行 Whisper 以获取语音转文本。\n关于LLM过度优化的一个有趣之处是，视觉模型的IO成本与文本模型不同。在文本模型中，正如我们在《亚马逊云危机》7一文中所描述的，它非常便宜。在视觉上，数据加载的IO约为150倍。每个图像 token 600字节，而文本则为4字节。目前正在进行大量的图像压缩工作。\n这对于那些针对2-3年后的LLMs优化硬件的硬件供应商非常相关。他们可能会发现自己生活在一个每个模型都具有强大视觉和音频功能的世界里。他们可能会发现自己的架构适应性较差。总的来说，架构肯定会超越我们今天所看到的基于当前简化文本的密集型和/或MoE模型。\n引用 Reference [1] The AI Brick Wall – A Practical Limit For Scaling Dense Transformer Models, and How GPT 4 Will Break Past It [2] On Device AI – Double-Edged Sword [3] AI Capacity Constraints - CoWoS and HBM Supply Chain [4] AMD MI300 – Taming The Hype – AI Performance, Volume Ramp, Customers, Cost, IO, Networking, Software [5] How continuous batching enables 23x throughput in LLM inference while reducing p50 latency [6] Clearly OpenAI does variable batch size based on usage volume…… [7] Amazon’s Cloud Crisis: How AWS Will Lose The Future Of Computing ","date":"2023-07-11T00:00:00Z","image":"/p/gpt4/banner_hu7c14224a355d073e1e2d02b641289c29_175300_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"/p/gpt4/","title":"【译】GPT-4详解——架构、基础设施、训练数据集、成本、愿景、MoE（混合专家模型）"},{"content":" 简介 北京的春天很美，但却很短。 我的等待穿越了漫长寒冷的冬季，直至春天的到来。 北京的春天似乎来得有些唐突，昨日还硬朗的风，今天就轻柔了许多。\n拍摄地点：海棠花溪、奥林匹克公园（新奥购物中心外）、八家郊野公园\n设备：Sony A7m2\n照片 ","date":"2023-04-02T00:00:00Z","image":"/p/2023spring/DSC00507_hu7ea319dd03bf41013c65479097a0d5a6_1164302_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"/p/2023spring/","title":"[摄影-风景] 2023北京的春天"},{"content":"注：AIGC（AI Generated Content，人工智能创作内容）\n天才就是1%的灵感加上99%的汗水，但那1%的灵感是最重要的，甚至比那99%的汗水都要重要。\n——爱迪生\n而AI技术的出现，在我看来，就是当我们有了那1%的灵感时，能让我们不需要或更少的付出汗水就能实现我们的想法。所以说，善于利用AI，还是得我们有想法，让后让AI技术帮我们实现。\n如果是在几年前，当你和你的小伙伴讨论AI会取代什么样的行业时，或是AI取代谁的工作时，我们会认为创造性工作（画画、作曲、作家等）会是难以被替代的。而现在事实证明，AI最有可能取代的反而是创造性工作。\n三大技术革命（农业，工业，IT）之后，AI或许（也可以去掉这两个字）将是第四个。\n前言 这一周，是神奇的一周。\n周一： Stanford 开源基于 LLaMA 的 Alpaca 7B\n周二：OpenAI 发布 GPT-4; Anthropic 发布 Claude; Google 公布 PaLM API; Google 将生成式 AI 加入 Workspaces; 清华智谱AI开源ChatGLM-6B; AdeptAI 融资 3.5 亿美元\n周三：Pytorch 2.0 发布; MidJouney5 发布\n周四：百度公布文心一言; Microsoft 公布 365 Copilot\n周五：我着手开始写这篇文章\n其中让我最兴奋的主要是两个方向和两个方面，两个方向分别是 大语言对话模型 和 基于扩散模型的图片生成，比如说Google的PaLM和GPT（Generative Pre-trained Transformer*）系列都是用于生成文本的大语言类Transformer模型，而MidJouney5和Stable Diffusion都是基于扩散模型的图片生成技术。\n*Transformer 是Google Brain 2017的提出的一篇工作，它针对RNN的弱点进行重新设计，解决了RNN效率问题和传递中的缺陷等，在很多问题上都超过了RNN的表现，发布之后被用于Google Translate中。在我看来，Transformer的提出意义不亚于ImageNet，属于是里程碑式的贡献。2017年，《Attention Is All You Need》论文首次提出了Transformer模型结构并在机器翻译任务上取得了The State of the Art(SOTA, 最好)的效果。2018年，《BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding》使用Transformer模型结构进行大规模语言模型（language model）预训练（Pre-train），再在多个NLP下游（downstream）任务中进行微调（Finetune）,一举刷新了各大NLP任务的榜单最高分，轰动一时。2019年-2021年，研究人员将Transformer这种模型结构和预训练+微调这种训练方式相结合，提出了一系列Transformer模型结构、训练方式的改进（比如transformer-xl，XLnet，Roberta等等）。如下图所示，各类Transformer的改进不断涌现。(进一步了解可移步这里) 两个方面一个是技术迭代，就像上一句话讲的那些，一个是应用创新，比如基于GPT-4用于Office的Copilot（其实之前Github推出过一个用于写代码的Copilot，那个也很强大，这个词的中文解释是副驾驶的意思，他就像飞机的副驾驶一样帮你完成那些你已经决定好要做的事情）。让我想到了很久以前的一个表情包：\n这是几年前看见的一些表情包，当时大家都觉得这基本上是不可能实现的，但随着Microsoft Copilot的发布，居然被实现了！具体的功能演示可以看一下这段视频：\nWow! Amazing! [哇]\n让ChatGPT写代码 我使用相机拍照的时候都会选择同时存储RAW与JPEG文件，通常在选照片以及给别人发照片的情况下使用JPEG文件，在修图的时候使用RAW文件。选图的时候我只会删除JPG文件，于是想编写一个脚本，能帮我自动删除对应的RAW文件，于是我去找了ChatGPT：\n他写出来的脚本居然可以真的直接使用，运行起来完全没有问题也能达到我想要的功能（把png改为arw），而且也对代码以及使用方法做出了详细的阐述！太神奇了！[惊讶]\n用Stable Diffusion画头像 目前深度学习领域比较主流的生成模型有GAN(对抗生成网络), VAE(变分自编码器), flow-based models(基于流的生成网络), diffusion models(扩散模型)几种。对于其更进一步的解读可以移步这篇文章。\n突发奇想，用它来画头像会不会很棒！之前看小红书呀b站呀许多画画的小伙伴接单画头像，于是我在朋友圈也展开了这个业务，与美术博主不同的是，我画头像是免费的，毕竟是使用AI绘图 [破涕为笑]。\n使用的是dalcefoPainting_v4模型（原作者似乎删库跑路了）。\nAIGC对产业的影响 AIGC对产业的各个行业的影响，远远超出我们的想象。如果让ChatGPT去答这个问题，都显得太过保守了。我们甚至从未想到过，AI甚至能取代模特。\n人工智能生成的文字和图片已经开始改变我们的工作与生活，并且将会在未来继续发挥越来越重要的作用。以下是一些例子： - 自动化工作流程：人工智能可以帮助我们自动化许多繁琐的工作流程，如数据录入、文件整理、文件分类等。这可以大大提高工作效率，让人类从重复性劳动中解放出来，专注于更有价值的工作。 - 智能客服：人工智能可以为客服提供支持，例如通过聊天机器人回答常见问题，自动分类和解决问题，提高客户满意度，减少人工客服的工作负担。 - 智能创作：人工智能可以生成各种形式的创意，如音乐、绘画、写作等。这可以使创意产生更多可能性，激发创作者的灵感，并提高创作的效率。 - 自动化决策：人工智能可以通过对大量数据的分析和学习，自动化决策过程，例如贷款审批、股票交易等。这可以提高决策的准确性和效率，减少错误和风险。 - 智能医疗：人工智能可以通过对医疗数据的分析和学习，提供更准确的诊断和治疗方案。这可以改善医疗质量，减少医疗资源的浪费，提高医疗效率。 总之，人工智能生成的文字和图片将会在很多方面改变我们的工作与生活，提高效率、准确性和创造力，让我们更加聪明和高效。 ——ChatGPT\n我们会因此失业吗 尽管人工智能和自动化技术的普及可能会导致一些工作的减少或消失，但在另一方面，这些技术也将为新的就业机会和工作模式创造空间。实际上，人工智能技术的发展已经带来了一些新的工作领域，例如机器学习工程师、数据科学家、AI产品经理、智能客服工程师等等。 此外，人工智能技术可以帮助提高工作效率和精度，使得企业可以通过减少人力成本来降低产品或服务的价格。这可以促进市场的发展，带来更多的经济机会和就业机会。 当然，在人工智能和自动化技术的普及过程中，我们也需要采取一些措施来确保劳动力的可持续性和稳定性，例如提供教育和培训来帮助人们适应新的工作模式，以及实行社会保障政策来保障受影响的人们的基本权益。 综上所述，人工智能和自动化技术的发展会改变一些就业机会，但同时也会创造新的就业机会，同时也需要采取一些措施来确保劳动力的可持续性和稳定性。\n——ChatGPT\n当然，部分人对AI的抵触情绪的些竟有可能会影响到自己的工作和收入，最近频繁在微博和小红薯能看到一些人对AI的抨击 (特别是一些模特、coser、画家、摄影、拍写真、搞颜色，这些是最快被替代的)，但时代的车轮开始转动的时候，会毫不留情的碾压没能及时上车的人，随着时间的推移，人类会在越来越多的领域上输给AI。大多数人根本连上车的机会都没有。我们可以同情，却无可奈何。\n好在，我是从事AI技术研发的[旺柴]。\n安全与局限性 \u0026ldquo;A double-edged sword cuts both ways.\u0026rdquo;\n难以辨别真伪 俗话说的好，“有图有真相”，但是随着P图的出现，可能很多图片也不可信了。而AI绘图的出现，让P图门槛进一步降低。\n虽然图像和视频可以为我们提供某些信息，但它们并不总是完全可信的。有时候图像和视频可以被编辑和篡改，以达到欺骗的目的。此外，有时候图像和视频也可能只提供了事件的片段，缺乏背景和上下文信息，从而导致我们对事实的真相做出错误的推断。 因此，尽管有图像或视频作为证据可以增加确定事实真实性的可信度，但我们仍然需要谨慎地评估这些证据，并考虑是否需要其他信息来完整地了解事实的真相。\n——ChatGPT\n最近，“广州地铁三号线裸照事件”冲上热搜，具体的内容各位可以在各种搜索引擎进行搜索，但是基于AI的绘图技术无疑是为了这种犯罪拉低了门槛。\n下图的左边是在卖衣服的服装商场常见的假人模型，通过Stable Diffusion的局部重绘功能加上描述词，我们可以将假人的脸换的看起来像真人一样。\n当然，这个技术被合适的运用可以得到很强的生产力和很棒创意表达，但是被不合理运用，比如涂抹掉衣服并加上类似于(nude, nsfw)这样的tag，产生的图片将不堪设想。不过，技术无罪。\n(问：为什么说“技术无罪”？)\n“技术无罪”是一种说法，意味着技术本身并没有好坏之分，它们只是工具和手段。技术的好坏是由使用它们的人所决定的。\n这种说法源于欧洲法学中的“罪刑不祖”原则，即罪行的存在必须要有相应的法律规定，而仅仅是使用某种工具并不能成为罪行。\n举个例子，刀具可以用来切菜、切肉等日常生活中的用途，也可以被用来犯罪，如杀人、伤人等。但是，我们不会因为它被用来犯罪而谴责刀具本身，而是谴责使用它的人。\n同样地，计算机技术、网络技术等也可以被用来创造和分享知识、促进社会进步和发展，但也可以被用于非法行为，如网络攻击、网络诈骗等。因此，技术本身并不是好坏的标准，而是取决于使用它的人的道德和行为准则。\n技术的正当性和合法性，需要符合法律、道德、人类价值观等各方面的要求。技术的发展也需要伴随着社会、法律、伦理等方面的规范和监管。只有在这样的框架下，技术才能真正为人类的福祉和发展服务，而不是成为人类的灾难。\n——ChatGPT\nAI的“幻觉” 未来的展望 多模态 数字永生 ","date":"2023-03-19T00:00:00Z","image":"/p/thinkaboutai/banner_huc8a375384e5b63ad140c58eca88663ff_140028_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"/p/thinkaboutai/","title":"关于对于AIGC的一些思考"},{"content":" 前言 2022年的绝大多数时间，都是在基于清零政策的疫情防控下度过的，因此错过了最后半学期的校园时光（大四下整个在家中度过的），失去了毕业典礼、拍毕业照、毕业旅行……\n在最后一个月，由于某些众所周知的原因迎来了突如其来的放开，让绝大多数在前三年对新冠“只闻其名”的人们突如其来的感受到了它的“温暖”（物理上的，体温），猝不及防的给疫情画上了一个句号。于是在放开之后，果不其然，我也阳了。\n为了弥补2022年的遗憾，在我阳康之后，策划了一场旅行计划，所以今年的年度总结有一点点不一样，先从2023年初的旅行讲起。在下文中尽量避开“疫情”这个话题，并且着重于通过一些事情进行的思考，而不仅仅是“朋友圈合订本”。\n此处附上一首BGM：给你一瓶魔法药水——告五人，最近比较喜欢的一首歌，可以边听边往下看。\n旅行 其实这场旅行是在2022年底策划的，但是最后处理完许多事情然后敲定好时间，决定1.3开始这次旅行，返回时间待定。初步规划的顺序是北京-\u0026gt;长沙-\u0026gt;深圳-\u0026gt;广州-\u0026gt;桂林-\u0026gt;北京，除往返北京乘坐飞机外，其余乘坐高铁。\n长沙——人间烟火气 李克强称赞地摊经济、小店经济：是人间的烟火，是中国的生机。\n来到长沙，给我的第一印象就是：长沙的人说普通话很有意思！尤其是刚去点茶颜悦色的时候，让我想起来了我一个同学——古乃草（大家可以去关注她的b站，去云南的两个视频真的很棒），她是一个湖南的妹子，到长沙的时候感觉大家说话都很像她！\n长沙（在我眼中）是一个以小吃和夜生活著称的城市，以及其举世闻名的茶饮料：\n茶颜悦色在奶茶类饮料中算是很好喝的，不同于Coco这种使用红茶+植脂末+糖浆制作的奶茶，茶颜悦色使用牛奶加茶制作，并加上了往往在咖啡中才会有的奶泡，并在其中几款中配备了动脂奶油的奶油顶，使得其又好看又好喝，简直就是来长沙必点品。\n长沙的茶颜悦色可以说是到处都是，走几步就有一家，并且茶颜悦色还有游园会，可以购买一些相关的周边产品。\n此外呢初次来湖南，不得不吃的当然是湖南菜啦：\n湘菜，亦称湖南菜，是具有鲜明湖南地方特色菜肴的统称。湘菜以辣味丰富适当、制作严谨、突出菜肴本味而著名。湘菜是中国八大菜系之一，因此于海外，湘菜被视作中国菜的代表之一。\n好吧，对我来说就是，湘菜好辣🌶！我在北京感觉我还算比较能吃辣的，但是吃湘菜还是得说一句“少放辣”，不过很多地方会跟你说少放辣做不了，“辣椒炒肉少放辣椒怎么做啊”。\n长沙的凌晨两三点，是我在北方从未见过的一番景象。\n这里是传说中的解放西路，B站知名纪录片《守护解放西》就是讲的这里。这一条街上有着密密麻麻的饭馆、小吃摊和酒吧等，可能是长沙夜里最热闹的地方之一。\n文和友是在室内建了一些看起来像室外的这种建筑，复古了当年老长沙的样子，还是值得来逛逛的，具体可以在小红书上搜一下~\n这部分邀请一个朋友（雅诗姐姐）当模特拍了几张。\n最后附上一份一个在长沙认识的朋友分享给我的旅行攻略：\n长沙旅游推荐：(点击查看全文)\n1.\u0026nbsp;省博物馆（必去，提前几天买票）\n2.\u0026nbsp;橘子洲（主要是为了毛爷爷，感受一下沁园春）\n3.\u0026nbsp;岳麓山：脚下就是湖南大学，夏天的时候日出文化可流行了，都没站的地方。\n4.\u0026nbsp;杜甫江阁：那边很多中年轻人在那边打发自己的业余时间，吹弹拉唱写打牌\n5.\u0026nbsp;太平老街的《臭豆腐博物馆》（可以看看，试试里面的臭豆腐，不同于黑色经典，黑色经典的大肉肠也可以试试，或者打卡冬瓜山大肉肠）\n6.\u0026nbsp;长郡中学门口的《金记》糖油粑粑\n7.\u0026nbsp;长郡中学门口的《左姑娘泡菜》，《金花泡菜》，爱吃泡菜的一定要尝尝哇\n8.\u0026nbsp;茶颜的每一款都很绝，更绝的是周边也超美，所以一定要积会员卡积分啊\n9.\u0026nbsp;《吴酥生》的冰淇淋泡芙和绿豆糕（每次来都要点好吧），或者都正街的《258》，七八种口味的绿豆糕，自带一股清香。\n10.\u0026nbsp;《巷子猪脚》（夜宵店，开了十几年了，味道很绝，但是非常辣，还原长沙辣度）\n11.\u0026nbsp;《公交新村粉》（必打卡好吧）\n12.\u0026nbsp;《笨萝卜》（黄兴广场那边，便宜又好吃，但是得提前一两小时排队！！）\n13.\u0026nbsp;太平老街的《酒怪》小酒馆（都是自酿的酒，值得一试，环境也很特别），还有南门口店的《杨嗲甜酒》（这家必须好吧）\n14.\u0026nbsp;《金碗牛肉》总店（每一个菜都很好吃，提前预订，不然招牌菜会售完）\n15.\u0026nbsp;来长沙也想吃烧烤的话，那一定要去《客串》啦！！（都正街店，超级多明星吃过，必点小黄鱼）\n16.\u0026nbsp;在长沙想吃烤肉的话，可以吃《么子烤肉》\n17.\u0026nbsp;要感受一下民谣吧的氛围的话，可以去都正街的《忘浮沉藏式酒吧》\n18.\u0026nbsp;《炊烟时代》的小炒黄牛肉\n19.\u0026nbsp;第一光头粉\n20.\u0026nbsp;聚味瞿记龙虾堂（五一广场店，每一道菜都非常好吃，缺点就是要提前排队）\n21.\u0026nbsp;桂香南县麻辣肉（比绝味好吃）\n22.\u0026nbsp;国金中心的探鱼也不错 深圳——改革开放的现代繁荣 “1979年，那是一个春天，有一位老人，在中国的南海边，划了一个圈……”\n——《春天的故事》\n深圳作为一个沿海城市，在冬天去真的很舒服。在欢乐港湾那边的海边的草地上坐着，看着大海和旁边的摩天轮，很是惬意。并且“来了就是深圳人”的这句宣传语，让每一个来到深圳的无论是游客还是打工人，都能感受到这个城市的温度。（至少北京是不会说出“来了就是北京人”这种话的）\n是的，我就像图中的这些人们一样，在这里坐着，想一想人生，选一选前几天的照片。中午和卷卷与流水老师从壹方城吃完八合里牛肉火锅之后走到了这里，by the way 卷卷是一个很有意思的人。\n其实来深圳，很重要的一点是来一个在数码电子方面听了很多次的地方：\n华强北，是我从小就听过的一个词语，也是自从我开始对电子和数码产品产生热爱之后听过最多的一个国内的地名。从上小学初中那会儿买手机流行买“水货”的苹果三星，到后来的美版iPhone魔改卡贴、高仿AirPods和原装实现一样的功能、给手机扩容等等等等，总觉得华强北是个很神奇的地方。\n正好，2022年年底从同学那里收来了一台二手MacBook Pro 13（2018款，8+512），除了显示屏内屏坏了以外，其他都没毛病，成色相当新，花了两千出头。正好想着之后去华强北，给它换块屏的同时，把内存扩大到16G。去华强北是现在淘宝上联系了个店家然后直接去的，整体比较顺利。华强北这边维修还是很不错的，是当着你的面维修，只要你不嫌无聊，你就可以坐在旁边看着他修。换屏的时候我是全程看着他干的，扩容内存的时候由于搞BGA的时间还是比较长的，正好加上要到饭点儿了所以吃完饭回来拿的。\n附上前后对比图，换屏花了500块钱，是非原装的屏幕，有一点点过饱和；升级到16G内存也花了500块钱，总之也是第一次知道MacBook的内存和硬盘都能升级。\n去华强北的时候叫上了在深圳的两个朋友——水池老师和卡卡姐。华强北这个地方除了卖电子数码产品之外，还有购物中心什么的，我们当晚还在那里吃了椰子鸡。\n深圳可以叫的上来名的景点少之又少，晚上去世界之窗吧，是因为它刚好那天有烟火表演🎆！这几年在北京生活已经很久没看过烟花了，潦草的放几张照片吧~\n等不到天黑，烟火不会太完美。\n——《她说》林俊杰\n弘法寺位于中国广东省深圳市罗湖区仙湖植物园内，背靠梧桐山，是一座汉传佛教寺院。\n去的那天正好赶上下小雨🌧，颇有一番仙境的的感觉。拍照挺好看的！此外，由于它在仙湖植物园内，能看见许多我在北方看不到的植物。\n哦对，在南油附近发现了一加比较小的店，做的肠粉真的很好吃！来观看一下做肠粉的视频吧！\n他家的肠粉可以说是又便宜又好吃了，比许多有名的连锁品牌要好吃的多。\n广州——老广东特色 在深圳的时候，可能并不觉得有特别多的广东特色，身边的人都讲着普通话，吃饭的馆子也和北京没有多大的区别，但是来到广州，就是一番截然不同的感觉了。\n刚到广州的第一天晚上，来到了老城区这边——越秀区，从上下九步行街一路走到了永庆坊。当天也是有一点点下雨，湿漉漉的路面上反射着地面上的灯光，有一种老城区独有的热闹。\n正好是一个广州的学妹带我来逛这里，在广州本地人点菜都是用粤语来点菜的。去了附近的东湖酒楼(永庆坊店)，是一家老字号的粤菜馆。这个烤乳鸽简直是太好吃了！第一次吃就被惊艳到了，这次旅行吃了三四只鸽子还是他们家的最好吃！\n顺便帮学妹拍了一些照片，还是很好看的！\n第二天去了番禺去找七七同学。\nTODO: 待补全 北京路 广州塔\u0026amp;珠江 越秀公园\n桂林——出名的自然风光 TODO: 待补全\nDaily 2022的daily由于众所周知的原因，可能没那么有趣，主要是干饭为主（这里就不发吃的了，感兴趣的不如去看我朋友圈）。想来想去，不如挑几件事儿来说一说吧。\n春游 每年的三四月份其实都回去玉渊潭看樱花，今年也不例外，玉渊潭也毫不例外的人山人海。\n京城柳初绿，玉渊樱已红。\n野餐 由于北京五六月份的一段时间不让堂食，所以我和小伙伴们决定去野餐！于是搬上桌子和椅子，带上卡式炉、鸳鸯锅和火锅食材，找了一片没有人的小森林，我们就开始野餐啦！在吃完火锅过后，我们拿了一副扑克牌开始打牌，很快乐~\n志愿者 今年正好赶上北京举办2022冬奥会，后来寒假期间有一天群里发了一个冬残奥会城市志愿者的补充报名活动，大概是又缺岗位了问有没有同学想要去，我就顺手报了一个。当志愿者还是很有意思的！\n城市志愿者的工作内容比较简单，主要是为了疏导观众、和观众打招呼什么的，相当于冬残奥气氛组。\nThinking 年终总结吧，想写一点点更经过思考的东西在里面，而不是简简单单的介绍生活。我十分喜欢和朋友们聊天，也喜欢深入地交流或思考一些话题。\n（这部分总是忘，想到啥写啥吧）\n科技与生活 作为一个科技工作者吧，如何将科技让我们的生活变得更美好也是一个值得思考的话题。以下分享两个小小的事情，让我更加愿意在计算摄影与计算机视觉研究的这条道路上走得更远。\n计算摄影与拍星星 计算摄影是指使用数字计算而不是光学处理的数字图像捕获和处理技术。计算摄影可以提高照相机的能力，或者引入基于胶片的摄影根本不可能的特征，或者降低照相机元件的成本或尺寸。\n2022年秋天的一个晚上，正当我带着有些许难过的心情打算在小区附近的小河边散步的时候，​偶然一抬头，发现天空中好多星星。感觉到这个景色真好看，正好想到了Google Camera有Night Sight模式，于是拿出手机，尝试拍下来。本来对手机没报太大希望，结果居然拍出来了和我预想中能排到差不多的画面（因为之前玩摄影的经验告诉我，在恰当的参数设置下，其实夜晚相机拍出来的会比肉眼看到的还要好看），或许这也是算法提升带给人们生活偶然的一些小惊喜吧。\n这让我想起了2017年吧，我上高中的时候去澳大利亚，从悉尼飞往北京的航班上，在大约赤道上空的位置，我看见过我所见过的最好看的星空，但是当时打开手机拍摄一片漆黑，拿着相机也由于所需要的快门时间过长（ISO6400，光圈全开也需要三秒）而无法拍到一张清晰的照片，大概是这个样子。我当时就在想，如果能有现在的计算摄影技术，那么这一定是一张极为震撼的照片。\n就像拍星星一样，以往一个需要专业相机加上三脚架固定在某个位置才能拍出来的照片，现如今我们只需要拿着手机手持就可以拍出来。我相信随着科技的发展，拿出手机，无需专业摄影知识的每一个人，都能随手拍出一张想要的照片，也可以利用计算摄影所带来的宽容度来给后期调整带来丰富的空间。\n计算机视觉与照片的管理 我十分热爱拍照片，有时候只是把它当做一种记录或者说纪念，像写日记一样。许嵩的《摄影艺术》中有一句歌词“时光流转，谁还用日记本，往事有底片为证”，虽然底片被HEIF/HEIC这种高效的数字化的存储格式所取代，但也只是为了帮助我更高效更省空间的存储这些“日记”。我在Google Photos上备份了有超过十万张照片，Google Photos有着我认为商用环境中最棒的算法加持，在多年前就支持了使用自然语言搜索相册、人脸及物品识别、AI-based图像编辑等等。\n前几天晚上在思考人生的时候，随手拿起来了一个我放在床上的毛绒玩具。忽然觉得这个毛绒玩具已经陪伴我很多年了，想回忆一下过去，于是我打开手机上的Google Photos搜索了它，翻到了和它经过的点点滴滴。\n2017年的时候，我和当时的一个好朋友一起逛街，我们一起看到了这个白熊，我觉得它特别可爱，于是她就把它买了下来送给了我。\n之后上高三的时候，我抱着它去学校上课，不想听课的时候还可以垫着它睡觉。\n之后上大学的时候需要住宿舍，由于来到了沙河这么偏僻的地方上学，所以从家里搬了不少东西去陪着我，也包括这个白熊。\n它还和我当时在宜家新买的大狗勾陪着我一起写代码做实验🥺。\n与数字化的文字记录相比，照片在之前看来是一种更难于搜索和管理的载体，但是有了现在的基于计算机视觉的技术，这一点也不太需要担心了。反而，使用照片可以更加省事儿且逼真的记录下当时的场景。\n关于MBTI-ENFP 此处和几个ENFP的朋友交流的时候有一些感悟，这里可能主要的关键点是“外向”与“内向”吧。\nIdeal Match (理想匹配) 有人可能注意过MBTI性格测试结果给出了一张Compatibility Chart，里面大概讲了什么样的性格的人比较合得来。我们可以看到内向和外向的在一起是理想匹配。但是和朋友的聊天中在思考一个问题，如果我很外向和喜欢社交，真的能给内向的ta足够的安全感吗。\n什么是快乐星球 这是针对知乎上一个的问题：为何我发现在中国ENFP真的很少？ 的思考，和朋友们聊天更多的感觉是“感同身受”吧，但如何改变或者说把外向的人们汇集在一起或者说让整个社交变得更有趣，我们也没什么想法。\n目标与道路 和很多朋友聊过的一个问题就是，为什么学这个专业，或者说这个专业是你自己选出来的吗，感觉身边大多数人在上大学之前对于自己学什么是没有特别明确的想法的，很多朋友给出的答案是“我家里人帮我选的”、“听说这个专业好就业”、“我啥专业都报了，看分数到那个分数段就随缘学什么专业吧”等等。\n在我之前以为，大学里那些“大学霸”们会是那种对当前专业很有求知欲很热衷于探索的，比如我当时的大学委就是这样。年底的时候和一个朋友聊天，偶然发现她居然是她们专业的第一或第二，但是她对她们专业大概态度就是骂骂咧咧。于是我就问她，那你为什么不考虑换个专业或者说你是怎么学到成绩这么好的，她说她也不知道自己该学什么，让她学什么她都能学得很好。\n经常会思考，每个人为什么会学这个专业，我一直觉得计算机或者说编程并不是每一个人都适合的，虽然我不知道这个话说得有没有道理。但是确实，即使我就读于计算机专业，我刚上大学的时候也发现有的同学对计算机是完全不了解的。可能是我上大学之前对计算机这方面了解还比较多吧，上大学之后我经常觉得一些可能是称之为常识的东西，有的同学居然不知道。\n我在大学之后的目标以及方向也不是特别明确，但是我是热爱写代码和研究新事物的。所以在大学期间我感觉我似乎把许多技术都了解、尝试、浅浅的研究了一下，比如从单片机到操作系统，前后端数据库，桌面与移动端GUI程序开发，机器学习与图像处理什么的自己也都做过一些尝试并写过许多代码。我不认为那些专注于一个技术明确就业方向与像我这样都研究一遍最后也没有明确的就业方向的谁优谁劣，毕竟还有许多人大学毕业之后从事的工作与自己本科学的没什么关系。\n毕业、考研与读研 TODO: 待补全\n","date":"2023-02-01T00:00:00Z","image":"/p/2022to2023/2023banner_huefcdc23473a1d6462c14827255a34185_108826_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"/p/2022to2023/","title":"再见2022，你好2023——年度总结\u0026旅行总结\u0026杂谈"},{"content":"前言 国庆的时候，我的一个学弟朋友邀请我参加一次轰趴活动，其实无非就是去喝酒、玩游戏、唱歌、吃饭。最后一项活动就是喝酒了，顺便摇骰子猜点数。具体的规则可以上网上查一下，大概就是这样。\n此次游戏因为我们的骰子数量只有30个，我们有7个人参与此次活动，只够每个人4个骰子。\n概率初步计算 在游戏环节中，我们想过进行概率计算，由于当时在活动现场不适合思考这种问题，于是就简单的得出了“不是很好算”这个结论。不过要回答“什么时候喊开，胜率最大”这个问题，我们还是要用概率去计算。这不，第二天我就在想这个问题，由于本人的数学水平不是很好，所以使用了计算机代码对整个过程进行模拟，结果如下：\n也就是说在这种情况下，对于“5个1”的叫法，“开”他的胜率约为49%；对于“10个x”（1\u0026lt;x\u0026lt;7,x∈N），“开”他的胜率约为54%。\n进一步分析 对于这个游戏，我们再叫骰子之前，可以看一下自己有什么骰子。一般情况下，我们也会根据自己已经有的骰子，来决定我们要叫什么的。于是我们的代码也可以考虑到这一点，即已知部分信息然后计算概率。还是当前的人数和骰子数，假设我知道我现在有了2个1和2个4，那么我叫“12个4”的胜率足足有58%，远远高于不知道任何信息时“12个4”的胜率。\n编写工具 为了方便读者在实战中应用此理论，我根据上述介绍编写了一个小工具，可以计算概率，也可以帮助读者更好的理解本文中的内容。\n源代码：https://github.com/xianfei/xianfei.github.io/blob/master/content/post/dice/dice.html\n结束语 其实吧，喝酒玩骰子就是图一乐，遇到心仪的对象，自己多喝几杯也无妨。\n封面图片：https://unsplash.com/photos/pQyTChJwEDI\n","date":"2022-10-02T00:00:00Z","image":"/p/dice/banner_hu5ac7de94e2cab2249ae730fa84d6c453_316093_120x120_fill_box_smart1_3.png","permalink":"/p/dice/","title":"关于喝酒的时候玩骰子的一些概率计算"},{"content":"完整版毕业论文可在微信公众号Xianfei进行查看。\n目前该项目的英文版论文已被收录至IEEE ISMAR 2022-Adjunct中。（https://github.com/xianfei/SysMocap/blob/main/pdfs/ismar.pdf）\n该项目截至发稿前在Github已获得1.5k Stars，介绍视频在B站获得了2.7万赞及1.1万硬币。\n源代码：https://github.com/xianfei/SysMocap/\n毕业论文原文：https://github.com/xianfei/SysMocap/blob/main/pdfs/bylw.pdf\n前言 大学四年转瞬即逝，四年的时光让我学会了许多知识，而毕业设计作为本科期间最后一次自己独立实现自己想做的项目，希望能做一个前沿、有用、有趣的软件，在与指导老师一番沟通后，决定做一个用视频驱动虚拟形象的系统，也就是一个虚拟主播系统，可以选择自己的虚拟形象，并且让虚拟形象跟着自己动。\n当然，这个系统的开发对于我来说是个不小的挑战，它涉及了计算机视觉、计算机图形学、桌面图形界面程序开发、网络通信等知识。而且对于姿态评估及动作捕捉方面的前沿技术之前的学习生活中并没有了解，于是指导老师拿给我了Kinect（一个专门用于动作捕捉的硬件）并且让我了解了一些这方面的开源项目，并且跟我说明了我需要做什么——使用开源的算法获得到的动作数据来驱动虚拟形象的骨骼运动。并且，我也了解到了虚幻引擎、Unity等三维图形引擎的知识。\n技术方案 在开发过程中，研究并对比了多种现有的算法，但是许多算法的运行环境很苛刻，需要专业的计算机配置才能运行。而我希望我做的系统是大家都能用上的，让大家能够体会到科技的乐趣。\n在浏览这方面的开源项目时，突然发现了Google TensorFlow Blog上的一篇文章3D Pose Detection with MediaPipe BlazePose GHUM and TensorFlow.js，其中谈到了一种基于Web技术的3D人体关节点检测方法。诶！Web技术！这不正好提供了非常强大的可移植性和通用行吗！配合之前使用过的Electron框架，能开发出体验一流的跨平台桌面端GUI应用程序。\n当然，更好的是，这个叫做kalidokit项目还给出了源代码，它给出的Pipeline如下图所示：\n于是我就去研究了一下Mediapipe和kalidokit\n创新点 Mediapipe和kalidokit的帮助下已经可以完成毕业设计课题中的一大步了，但是kalidokit自带的demo只能驱动VRM类型的虚拟形象，而面对更常见的fbx、glb/gltf则无从下手。\n同时在实现任务书中的功能之后，我希望能够再加入一些实用的功能和前沿的功能。因为最近虚拟主播很火爆，所以该软件生成的虚拟形象需要实时应用于直播。于是设计了基于HTTP和WebSocket的虚拟形象及动作转发系统，并且为OBS直播软件专门设置了接口，使其可以直接被用于推流到主流平台中。\n但是目前常规的直播都是二维图像直播，在这个元宇宙即将来临的时代，AR/VR/MR（增强现实、虚拟现实与混合现实）必会成为主流趋势，所以我在想能不能定义一种全新的直播方式，可以让用户更为直观的看到对方的虚拟形象呢？于是就设计了基于WebXR技术的虚拟形象直播方案，用户只需要在支持WebXR的设备上访问该系统，即可实时的通过网络在周围环境中查看虚拟形象及其动作。就像科幻电影里面的那样，打开支持AR的手机或带上支持VR/MR的眼镜，虚拟形象就站在你的面前。\n主要来说要做的事情如下：\n使其可以驱动不同类型的虚拟形象\n为其编写一套简单易用好看的GUI\n支持OBS进行直播\n支持AR/VR展示\n难点 使其可以驱动不同类型的虚拟形象 面对这个工作，首先我了解3D模型的骨骼，3D模型之所以能动，是因为他有骨骼，也就是说3D模型有骨骼是能够让他动起来的必要条件。不同的虚拟形象模型，往往有着不同的骨骼结构及命名规则。图中为冰墩墩的骨骼（自己绑定的）和VRM虚拟形象的骨骼（自带的）。\n我们可以发现其骨骼数量是不一样的，其实命名方式也是不一样的，甚至骨骼的坐标系、运动方式都是不一样的，比如下图中三种不同的虚拟形象，做同样的动作时，对坐标的操作是不一样的。\n这或许是迄今为止首个可以支持多种不同虚拟形象格式、不同类型不同骨骼结构的虚拟主播软件。\nAR展示 在写上期的《AR冰墩墩》文章的时候，就是想着在毕设中可以实现AR冰墩墩跟着我做一样的动作。上期用到的\u0026lt;model-viewer\u0026gt;就是基于Three.js开发的，使用WebXR浏览AR内容。但是由于前者是高度封装的，我们想让虚拟形象实时的做指定的动作，需要对虚拟形象骨骼的控制能力。于是就用参考这篇文章编写了WebXR接口。\n这或许是迄今为止首个可以用来AR/VR直播的虚拟主播软件。\nGUI 一个好看的程序就让用户有更多想用的欲望。所以在界面设计上下了许多的功夫，比如采用了自动取色算法进行色彩搭配，比如在添加虚拟形象时的非线性动画，比如在删除虚拟形象时的粒子爆炸效果……\n这或许是迄今为止最好看的跨平台虚拟主播软件。\n结束语 在完成毕设的过程中，学到了许多计算机图形学的知识——比如欧拉角、旋转矩阵、四元数、球面插值等。\n之前我的一个朋友跟我说，她在一个她关注的公众号上看见了对我的毕设的介绍，我一看还真是。\n这篇文章中对我的毕设的评价是“杀疯了”😂\n其实只是想做点儿有趣的事情罢了\n附：毕设答辩PPT及讲解 P1: 首页/封面\nP2: 目录，答辩过程整个分为如下四个部分\nP3: Part 1 选题的背景与意义\nP4: 介绍虚拟主播在当下十分火热，很有前景\nP5: 但是现有方案存在如下四个难点使得不能被普及\nP6: 为了解决上述问题，所以我的毕业设计想要实现一个更简单易用的虚拟主播系统\nP7: 本毕设研究及工作内容如下：\nP8: Part 2 系统展示\nP9: 视频见 https://bilibili.com/video/av727029952\nP10: Part 3 研究过程与程序设计实现\nP11: 研究过程如下：\nP12-P13: 对现有的成果及算法进行调研\nP14: 对虚拟形象3D模型文件格式的研究\nP15: 对渲染程序的研究\nP16: 系统设计\nP17-P18: 模块架构\nP19: 动作捕捉模块采用实时设计（丢弃帧来换取实时性）\nP20: 骨骼转换算法示意图，设计了一套通用的骨骼转换算法\nP21-P22: 渲染/驱动虚拟角色方法及插值技术\nP23: 虚拟形象管理及文件结构\nP24: UI设计\nP25: 通信模块设计（动作数据转发）\nP26-P30: 应用场景举例\nP31: 使用的相关技术\nP32: 开发过程 - 使用Github Actions\nP33: Part 4 论文总结与致谢\nP34-P36: 贡献及致谢\nP37: 总结\n","date":"2022-08-29T00:00:00Z","image":"/p/bishe/sysmocap_hu556f2aae40812163569276577bc9cdb6_1336970_120x120_fill_box_smart1_3.png","permalink":"/p/bishe/","title":"来聊聊我的本科毕业设计吧"},{"content":" 2021 年 9 月，作为大四的最后一次小组开发课程，我们设计了一个有趣的社交软件——奶黄猫。我在小组中担任产品设计、前端/客户端开发的职位。\n演示视频 视频使用 AV1 格式编码，请使用 Chrome 70+ / Firefox 67+ / Edge 79+ 浏览器进行播放。See more on here.\n设计想法 在设计这个该社交软件时，由于我们小组都是来自同一个班学同一个专业的程序员，于是我就想到了一个很有意思的想法——将类似于小程序的应用嵌入到动态区域内，来增强可交互性和趣味性。目前的社交软件往往支持在动态除了文字外添加照片、视频等，向下方所展示的一样。\nXianfei A software engineer. Today I'm excited to tell you that we have just launched our new social app, Cream Cat. 666 favorite 666 chat_bubble 而我们认为动态的区域应该让用户自由发挥，所以我们设计了可编程动态，大大提高了社交软件用户动态的可交互性及可玩性。当你想与你的朋友分享一个小游戏时，你的朋友无需点开链接，即可直接进行游玩。\nXianfei A software engineer. What an interesting game! Try to play it bro! 666 favorite 666 chat_bubble 此外，对于编程初学者，可能只会编写CLI应用程序，我们也设计了CLI运行环境，方便编程初学者分享他们的学习成果。\n试想一下，刚上大学的你，学会了 C 语言，写下属于自己人生中的第一个程序时，那迫不及待想让亲朋好友体验的心情。而这个软件恰好能满足他们！\n核心技术 代码 https://github.com/xianfei/nhm-android-client/tree/main/app/src/main/assets/web\n接口文档 版本：2021-11-02 ver0.9 by xianfei\n备注 time 使用的为 Unix 时间戳，new Date().getTime()\n动态相关部分 获取动态\nHTTP 请求方式：POST\nURL： /moment/getMoments\nPOST Form：\n参数 说明 userID 用户唯一标识符 type 0 为广场 1 为关注 lastMomentID 上次获取最后一条动态的 ID，第一次获取为-1 length 本次获取的动态数 预期返回类型：Json Object\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\n​ [{\n​ \u0026ldquo;momentID\u0026rdquo;:当前动态ID,\n​ \u0026ldquo;userID\u0026rdquo;:用户ID，字符串,\n​ \u0026ldquo;userName\u0026rdquo;:用户昵称，字符串,\n​ \u0026ldquo;userAvatar\u0026rdquo;:用户头像，应为图片URL，字符串,\n​ \u0026ldquo;time\u0026rdquo;:此动态产生时间戳 整型,\n​ \u0026ldquo;text\u0026rdquo;:动态文字内容,\n​ \u0026ldquo;appendixType\u0026rdquo;:0无 1图片 2视频 3GUI程序代码段 4CLI程序代码段,\n​ \u0026ldquo;photos\u0026rdquo;:仅appendixType为1时读取该属性 为含一个或多个图片URL的数组 ,\n​ \u0026ldquo;video\u0026rdquo;:仅appendixType为2时读取该属性 此项为视频URL ,\n​ \u0026ldquo;appID\u0026rdquo;:仅appendixType为3/4时读取该属性,\n​ \u0026ldquo;likedNum\u0026rdquo;:点赞数 整型,\n​ \u0026ldquo;commentNum\u0026rdquo;:评论数 整型,\n​ \u0026ldquo;isLiked\u0026rdquo;:当前用户是否点赞了当前动态，Boolean,\n​ \u0026ldquo;isDel\u0026rdquo;:该动态是否已被删除，Boolean,\n​ \u0026ldquo;tag\u0026rdquo;:动态标签\n},{\n​ //同上\n}]\n}\n获取单个动态\nHTTP 请求方式：POST\nURL： /moment/getMomentByID\nPOST Form：\n参数 说明 userID 用户唯一标识符 momentID 动态的 ID 预期返回类型：Json Object\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\n{\n​ \u0026ldquo;momentID\u0026rdquo;:当前动态ID,\n​ \u0026ldquo;userID\u0026rdquo;:用户ID，字符串,\n​ \u0026ldquo;userName\u0026rdquo;:用户昵称，字符串,\n​ \u0026ldquo;userAvatar\u0026rdquo;:用户头像，应为图片URL，字符串,\n​ \u0026ldquo;time\u0026rdquo;:此动态产生时间戳 整型,\n​ \u0026ldquo;text\u0026rdquo;:动态文字内容,\n​ \u0026ldquo;appendixType\u0026rdquo;:0无 1图片 2视频 3GUI程序代码段 4CLI程序代码段,\n​ \u0026ldquo;photos\u0026rdquo;:仅appendixType为1时读取该属性 为含一个或多个图片URL的数组 ,\n​ \u0026ldquo;video\u0026rdquo;:仅appendixType为2时读取该属性 此项为视频URL ,\n​ \u0026ldquo;appID\u0026rdquo;:仅appendixType为3/4时读取该属性,\n​ \u0026ldquo;likedNum\u0026rdquo;:点赞数 整型,\n​ \u0026ldquo;commentNum\u0026rdquo;:评论数 整型,\n​ \u0026ldquo;isLiked\u0026rdquo;:当前用户是否点赞了当前动态，Boolean,\n​ \u0026ldquo;isDel\u0026rdquo;:该动态是否已被删除，Boolean,\n​ \u0026ldquo;tag\u0026rdquo;:动态标签\n}\n}\n点赞/取消动态（对于已点赞再次点赞为取消）\nHTTP 请求方式：POST\nURL： /moment/likeMoment\nPOST Form：\n参数 说明 userID 用户唯一标识符 momentID 点赞的动态 预期返回类型：Json Object\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:{\n​ \u0026ldquo;isLiked\u0026rdquo;:当前用户是否点赞了当前动态，Boolean,\n​ \u0026ldquo;likedNum\u0026rdquo;:该动态点赞数\n​ }\n}\n发送评论\nHTTP 请求方式：POST\nURL： /moment/commentMoment\nPOST Form：\n参数 说明 userID 用户唯一标识符 momentID 评论的动态 commentText 评论内容 预期返回类型：Json Object\n{\u0026ldquo;status\u0026rdquo;:0,\u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;}\n获取评论\nHTTP 请求方式：POST\nURL： /moment/getComment\nPOST Form：\n参数 说明 userID 用户唯一标识符 momentID 动态 ID 预期返回类型：Json Array\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:[{\n​ \u0026ldquo;commentID\u0026rdquo;:评论ID，字符串,\n​ \u0026ldquo;userID\u0026rdquo;:用户ID，字符串,\n​ \u0026ldquo;userName\u0026rdquo;:用户昵称，字符串,\n​ \u0026ldquo;userAvatar\u0026rdquo;:用户头像，应为图片URL，字符串,\n​ \u0026ldquo;time\u0026rdquo;:此评论产生时间戳 整型,\n​ \u0026ldquo;text\u0026rdquo;:内容,\n​ \u0026ldquo;likedNum\u0026rdquo;:点赞数,\n},{\n// 同上\n}]\n}\n获取点赞用户列表\nHTTP 请求方式：POST\nURL： /moment/getLikedMomentUsers\nPOST Form：\n参数 说明 userID 用户唯一标识符 momentID 动态 ID 预期返回类型：Json Array\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:[{\n​ \u0026ldquo;userID\u0026rdquo;:用户ID，字符串,\n​ \u0026ldquo;userName\u0026rdquo;:用户昵称，字符串,\n​ \u0026ldquo;userAvatar\u0026rdquo;:用户头像，应为图片URL，字符串,\n},{\n// 同上\n}]\n}\n发表纯文本动态\nHTTP 请求方式：POST\nURL： /moment/createMomentOnlyText\nPOST Form：\n参数 说明 userID 用户唯一标识符 text 文本内容 tag 标签 预期返回类型：Json Object\n{\u0026ldquo;status\u0026rdquo;:0,\u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;}\n发表含图片文本动态\nHTTP 请求方式：POST\nURL： /moment/createMomentWithPhotos\nPOST Form：\n参数 说明 userID 用户唯一标识符 text 文本内容 tag 标签 photos 多张图片文件* *参考 https://blog.csdn.net/qq_38310446/article/details/87623991\n预期返回类型：Json Object\n{\u0026ldquo;status\u0026rdquo;:0,\u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;}\n发表含视频文本动态\nHTTP 请求方式：POST\nURL： /moment/createMomentWithVideo\nPOST Form：\n参数 说明 userID 用户唯一标识符 text 文本内容 tag 标签 video 视频文件 预期返回类型：Json Object\n{\u0026ldquo;status\u0026rdquo;:0,\u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;}\n删除评论\nHTTP 请求方式：POST\nHTTP 请求方式：POST\nURL： /moment/delComment\nPOST Form：\n参数 说明 userID 用户唯一标识符 commentID 点赞的评论 预期返回类型：Json Object\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;\n}\n删除动态\nHTTP 请求方式：POST\nURL： /moment/delMoment\nPOST Form：\n参数 说明 userID 用户唯一标识符 momentID 动态 ID 预期返回类型：Json Object\n{\u0026ldquo;status\u0026rdquo;:0,\u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;}\n获取某用户动态\nHTTP 请求方式：POST\nURL： /moment/getUsersMoments\nPOST Form：\n参数 说明 userID 用户唯一标识符 targetUserID 需要获取对方动态的 ID lastMomentID 上次获取最后一条动态的 ID length 本次获取的动态数 预期返回类型：Json Object\n返回值同 1 获取动态\n获取某类型动态\nHTTP 请求方式：POST\nURL： /moment/getTagMoments\nPOST Form：\n参数 说明 userID 用户唯一标识符 tag 希望获取的动态类型 lastMomentID 上次获取最后一条动态的 ID length 本次获取的动态数 预期返回类型：Json Object\n返回值同 1 获取动态\n举报动态\nHTTP 请求方式：POST\nURL： /moment/reportMoment\nPOST Form：\n参数 说明 userID 用户唯一标识符 momentID 被举报动态 ID message 举报理由 预期返回类型：Json Object\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;\n}\n获取 CLI 程序段\nHTTP 请求方式：POST\nURL： /moment/getAppCLI\nPOST Form：\n参数 说明 appID 代码段唯一标识符 {\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:{\n​ \u0026ldquo;language\u0026rdquo;:编程语言,\n​ \u0026ldquo;code\u0026rdquo;:程序代码,\n​ \u0026ldquo;para\u0026rdquo;:保留段,\n​ }\n}\n发表含 CLI 程序段文本动态\nHTTP 请求方式：POST\nURL： /moment/createMomentWithAppCLI\nPOST Form：\n参数 说明 userID 用户唯一标识符 text 文本内容 tag 标签 language 编程语言 code 程序代码段 para 保留段 预期返回类型：Json Object\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;\n}\n获取 GUI 程序段\nHTTP 请求方式：POST\nURL： /moment/getAppGUI\nPOST Form：\n参数 说明 appID 代码段唯一标识符 {\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:{\n​ \u0026ldquo;language\u0026rdquo;:编程语言,\n​ \u0026ldquo;code\u0026rdquo;:程序代码,\n​ \u0026ldquo;html\u0026rdquo;:HTML代码,\n​ \u0026ldquo;css\u0026rdquo;:css代码,\n​ \u0026ldquo;para\u0026rdquo;:保留段,\n​ }\n}\n发表含 GUI 程序段文本动态\nHTTP 请求方式：POST\nURL： /moment/createMomentWithAppGUI\nPOST Form：\n参数 说明 userID 用户唯一标识符 text 文本内容 tag 标签 language 编程语言 code 程序代码段 html 代码 css 代码 para 保留段 预期返回类型：Json Object\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;\n}\n用户相关 获取某用户信息\nHTTP 请求方式：POST\nURL： /user/getUsersInfo\nPOST Form：\n参数 说明 userID 请求的用户 ID targetUserID 对方动态 ID 预期返回类型：Json Object 对象数组\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:{\n​ \u0026ldquo;userID\u0026rdquo;:用户ID，字符串,\n​ \u0026ldquo;userName\u0026rdquo;:用户昵称，字符串,\n​ \u0026ldquo;userAvatar\u0026rdquo;:用户头像，应为图片URL，字符串,\n​ \u0026ldquo;follower\u0026rdquo;:粉丝数,\n​ \u0026ldquo;following\u0026rdquo;:关注数,\n​ \u0026ldquo;isMale\u0026rdquo;:性别,\n​ \u0026ldquo;description\u0026rdquo;:个性签名,\n​ \u0026ldquo;tag\u0026rdquo;:用户喜好标签,\n​ \u0026ldquo;relationship\u0026rdquo;:0无 1是粉丝 2已关注 3互相关注 ​ }\n}\n修改用户信息\nHTTP 请求方式：POST\nURL： /user/changeUsersInfo\nPOST Form：\n参数 说明 userID 用户唯一标识符 userName 用户昵称 isMale 性别 description 个性签名 tag 用户喜好标签 预期返回类型：Json Object 对象数组\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;\n}\n登录\nHTTP 请求方式：POST\nURL： /user/login\nPOST Form：\n参数 说明 user 用户 ID/手机号 password 密码 预期返回类型：Json Object 对象数组\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:{\u0026ldquo;userID\u0026rdquo;:用户唯一标识符}\n}\n修改头像\nHTTP 请求方式：POST\nURL： /user/changeAvatar\nPOST Form：\n参数 说明 userID 用户 ID img 头像 预期返回类型：Json Object 对象数组\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;\n}\n注册\nHTTP 请求方式：POST\nURL： /user/register\nPOST Form：\n参数 说明 userID 手机号 password 密码 userName 用户昵称 isMale 性别 预期返回类型：Json Object 对象数组\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:{\u0026ldquo;userID\u0026rdquo;:用户唯一标识符}\n}\n修改密码\nHTTP 请求方式：POST\nURL： /user/changePassword\nPOST Form：\n参数 说明 userID 用户 ID passwordOld 原密码 passwordNew 新密码 预期返回类型：Json Object 对象数组\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;\n}\n获取粉丝列表\nHTTP 请求方式：POST\nURL： /user/getFans\nPOST Form：\n参数 说明 userID 请求的用户 ID targetUserID 对方动态 ID 预期返回类型：Json Object 对象数组\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:[{\n​ \u0026ldquo;userID\u0026rdquo;:用户ID，字符串,\n​ \u0026ldquo;userName\u0026rdquo;:用户昵称，字符串,\n​ \u0026ldquo;userAvatar\u0026rdquo;:用户头像，应为图片URL，字符串,\n​ \u0026ldquo;relationship\u0026rdquo;:0无 1是粉丝 2已关注 3互相关注\n​ },{同上}]\n}\n获取关注列表\nHTTP 请求方式：POST\nURL： /user/getFollowers\nPOST Form：\n参数 说明 userID 请求的用户 ID targetUserID 对方的 ID 预期返回类型：Json Object 对象数组\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:[{\n​ \u0026ldquo;userID\u0026rdquo;:用户ID，字符串,\n​ \u0026ldquo;userName\u0026rdquo;:用户昵称，字符串,\n​ \u0026ldquo;userAvatar\u0026rdquo;:用户头像，应为图片URL，字符串,\n​ \u0026ldquo;relationship\u0026rdquo;:0无 1是粉丝 2已关注 3互相关注\n​ }\n​ ,{同上}]\n}\n举报用户\nHTTP 请求方式：POST\nURL： /user/reportUser\nPOST Form：\n参数 说明 userID 用户唯一标识符 targetUserID 被举报用户 message 举报理由 预期返回类型：Json Object\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;\n}\n关注用户\nHTTP 请求方式：POST\nURL： /user/followUser\nPOST Form：\n参数 说明 userID 用户唯一标识符 targetUserID 被关注用户 id 预期返回类型：Json Object\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;\n}\n搜索用户\nHTTP 请求方式：POST\nURL： /user/searchUser\nPOST Form：\n参数 说明 userID 请求的用户 ID queryUserName 查询的用户名 预期返回类型：Json Object 对象数组\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:[{\n​ \u0026ldquo;userID\u0026rdquo;:用户ID，字符串,\n​ \u0026ldquo;userName\u0026rdquo;:用户昵称，字符串,\n​ \u0026ldquo;userAvatar\u0026rdquo;:用户头像，应为图片URL，字符串,\n​ \u0026ldquo;relationship\u0026rdquo;:0无 1是粉丝 2已关注 3互相关注\n​ }\n​ ,{同上}]\n}\n取消关注用户\nHTTP 请求方式：POST\nURL： /user/cancelFollowUser\nPOST Form：\n参数 说明 userID 用户唯一标识符 targetUserID 被关注用户 id 预期返回类型：Json Object\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:\u0026quot;\u0026quot;\n}\n通知 获取通知\nHTTP 请求方式：POST\nURL： /notice/getNotice\nPOST Form：\n参数 说明 userID 请求的用户 ID 预期返回类型：Json Object 对象数组\n{\n​ \u0026ldquo;status\u0026rdquo;:0,\n​ \u0026ldquo;message\u0026rdquo;:[{\n​ \u0026ldquo;type\u0026rdquo;:1新粉丝 2评论 3点赞 4系统公告,\n​ \u0026ldquo;userID\u0026rdquo;:用户ID，字符串，type为4时不检查此属性,\n​ \u0026ldquo;userName\u0026rdquo;:用户昵称，字符串，type为4时不检查此属性,\n​ \u0026ldquo;userAvatar\u0026rdquo;:用户头像，应为图片URL，字符串，type为4时不检查此属性,\n​ \u0026ldquo;note\u0026rdquo;:信息内容,\n​ \u0026ldquo;momentID\u0026rdquo;:仅type为2或3时使用此值，其余不检测该属性,\n​ \u0026ldquo;time\u0026rdquo;:当前通知产生时间\n​ }\n​ ,{同上}]\n}\n聊天 发送消息\n协议：WebSocket 全双工\nURL：/chat\n数据报类型：JSON\n数据报格式：\n{\n​ \u0026ldquo;formUserID\u0026rdquo;:发送消息的用户ID,\n​ \u0026ldquo;toUserID\u0026rdquo;:接收消息的用户ID,\n​ \u0026ldquo;message\u0026rdquo;:消息体\n}\n","date":"2022-07-10T00:00:00Z","image":"/p/nhm/nhm_hue7dded98aae76fa85d959422e4468917_273341_120x120_fill_box_smart1_3.png","permalink":"/p/nhm/","title":"我们设计了一个有趣的社交软件——奶黄猫"},{"content":"什么是 WebAssembly？ WebAssembly (abbreviated Wasm) is a binary instruction format for a stack-based virtual machine. Wasm is designed as a portable compilation target for programming languages, enabling deployment on the web for client and server applications.\n― webassembly.org WebAssembly 是一种新的编码方式，可以在现代的网络浏览器中运行 － 它是一种低级的类汇编语言，具有紧凑的二进制格式，可以接近原生的性能运行，并为诸如 C / C ++等语言提供一个编译目标，以便它们可以在 Web 上运行。它也被设计为可以与 JavaScript 共存，允许两者一起工作。\n对于网络平台而言，WebAssembly 具有巨大的意义——它提供了一条途径，以使得以各种语言编写的代码都可以以接近原生的速度在 Web 中运行。在这种情况下，以前无法以此方式运行的客户端软件都将可以运行在 Web 中。\nWebAssembly 被设计为可以和 JavaScript 一起协同工作——通过使用 WebAssembly 的 JavaScript API，你可以把 WebAssembly 模块加载到一个 JavaScript 应用中并且在两者之间共享功能。这允许你在同一个应用中利用 WebAssembly 的性能和威力以及 JavaScript 的表达力和灵活性，即使你可能并不知道如何编写 WebAssembly 代码。\n以上三段内容来自 MDN： https://developer.mozilla.org/zh-CN/docs/WebAssembly\n安装编译器 首先我们需要安装一个 WebAssembly 编译器emscripten。对于 macOS 可使用 brew 进行安装\n1 brew install emscripten 测试 emscripten 是否安装成功 此处我们可以运行emcc和emcc --version来测试是否安装成功。\n在 Web 中运行 C 语言代码 C++由于对函数重载、面向对象、名字空间（namespace）等的支持，使得其符号名（mangled symbols）不如 C 语言直观，本文先使用 C 语言进行演示。\n编写 C 代码 下面我们编写一个非常简单的 C 语言例子，它将会返回两数之和，在你所使用的工作目录下，创建一个 test.c 文件。\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;emscripten/emscripten.h\u0026gt; // 一旦WASM模块被加载，main()中的代码就会执行 int main(int argc, char ** argv) { printf(\u0026#34;WebAssembly module loaded\\n\u0026#34;); } // 返回两数之和 int EMSCRIPTEN_KEEPALIVE get_sum(int a,int b) { return a + b; } 将 C 编译为 WebAssembly 现在我们已经有了 C 代码，接下来需要将它编译成 wasm，不仅如此，我们还需要生成相应的 JavaScript 胶接代码以便能够真正运行起来。\n1 emcc test.c -s WASM=1 -O2 -o index.js 各个参数含义如下：\nemcc——代表 Emscripten 编译器； test.c——包含 C 代码的文件； -s WASM=1——指定使用 WebAssembly； -O2——代码优化级别； -o index.js——指定生成包含 wasm 模块所需的全部胶接代码的 JS 文件； 编译完成后，会生成 index.js 与 index.wasm 文件。\n编写 HTML 代码 在浏览器中处理 WebAssembly 有一个非常强大的 API 可以使用，在此我们不会进行深入探讨因为这已经超出了入门的范畴，我们只需要 Module 接口及其 ccall 方法这部分即可。该方法允许我们通过函数名从 C 代码中调用一个函数，然后就向一般的 JS 函数一样使用就行了。\n1 2 3 4 5 6 var result = Module.ccall( \u0026#34;funcName\u0026#34;, // 函数名 \u0026#34;number\u0026#34;, // 返回类型 [\u0026#34;number\u0026#34;], // 参数类型 [42] ); // 参数 调用此方法之后，result 就将拥有对应 C 函数的所有功能，除函数名以外的所有参数都是可选的。\n我们也可以使用缩写版（使用符号名）：\n1 var result = _funcName(args...); 接着我们需要编写一个 HTML 文件，此处命名为 index.html，包含一个按钮和一个 div 块用来显示结果。\n然后我们添加一个 script 标签用来编写在 JavaScript 中调用 wasm 模块的代码。由于胶接代码的存在（index.js），这项任务变得非常简单，它已经为我们处理好了所有的接线任务。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;WebAssembly 示例\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;button id=\u0026#34;run\u0026#34;\u0026gt;执行！\u0026lt;/button\u0026gt; \u0026lt;div id=\u0026#34;result\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;index.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; // 当按钮被点击时，其值将会被改变 var runButton = document.querySelector(\u0026#34;#run\u0026#34;); runButton.addEventListener(\u0026#34;click\u0026#34;, function () { // 调用C代码中的get_sum函数 var result = _get_sum(2, 4); document.querySelector(\u0026#34;#result\u0026#34;).innerText = result; }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 然后访问该网页，此处使用VSCode的Live Server插件进行访问（其他HTTP文件服务器也可以），不能通过直接打开html文件的方式运行（由于CORS本地文件限制）\n那么，C++呢？ 首先，先将上面的代码转换为C++代码，并保存为test.cpp文件。\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;iostream\u0026gt; #include \u0026lt;emscripten/emscripten.h\u0026gt; // 一旦WASM模块被加载，main()中的代码就会执行 int main(int argc, char ** argv) { std::cout \u0026lt;\u0026lt; \u0026#34;WebAssembly module loaded\u0026#34; \u0026lt;\u0026lt; std::endl; } // 返回两数之和 int EMSCRIPTEN_KEEPALIVE get_sum(int a,int b) { return a + b; } 然后使用相同的方式进行编译。\n1 emcc test.cpp -s WASM=1 -O2 -o index.js C++有着复杂的Symbol Mangling规则，我们不妨先从标准C++文件进行分析，使用g++编译后使用nm命令分析符号，如下图。\n我们看到，我们所编写的函数符号名为__Z7get_sumii，于是可以使用该符号名调用此函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34; /\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34; /\u0026gt; \u0026lt;title\u0026gt;WebAssembly 示例\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;button id=\u0026#34;run\u0026#34;\u0026gt;执行！\u0026lt;/button\u0026gt; \u0026lt;div id=\u0026#34;result\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;index.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt; // 当按钮被点击时，其值将会被改变 var runButton = document.querySelector(\u0026#34;#run\u0026#34;); runButton.addEventListener(\u0026#34;click\u0026#34;, function () { // 调用C++代码中的get_sum函数 var result = __Z7get_sumii(2, 4); document.querySelector(\u0026#34;#result\u0026#34;).innerText = result; }); \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 我们通过DevTools查看WebAssembly反汇编代码，也可以证实这一点\n","date":"2022-06-01T00:00:00Z","image":"/p/wasm/wasm_hu9cd79e3bd4f8565d3c544d147212ce46_404011_120x120_fill_box_smart1_3.png","permalink":"/p/wasm/","title":"WebAssembly了解一下！"},{"content":"前言 去年考完研，打算学一学Python要如何调用机器学习的库，之前只会一些Flask的基本操作。\n这是一个基于xyolo库搭建的Web图片目标识别项目，（属于没事儿写着玩地那种），前端使用了纯原生开发（去年写这个东西的时候还不会Vue），后端API部分使用的flask，代码极为简单。\n预览 这里有几张图片，方便大家看一下这个东西最后是个什么效果，图中不同颜色的框框是由前端div绘制，并且识别结果tag也是由html绘制的。在最后还绘制了一个用于显示识别结果和准确率的表格。\n实现 后端代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 import numpy from xyolo import YOLO, DefaultYolo3Config from xyolo import init_yolo_v3 from flask import Flask, jsonify, request from flask_cors import CORS from PIL import Image app = Flask(__name__) CORS(app, resources=r\u0026#39;/*\u0026#39;) config = DefaultYolo3Config() init_yolo_v3(config) yolo = YOLO(config) @app.route(\u0026#39;/postimg\u0026#39;, methods=[\u0026#39;POST\u0026#39;]) def hello_world(): img = Image.open(request.files[\u0026#39;file\u0026#39;].stream) result = yolo.detect_image(img) print(result) return jsonify({\u0026#39;result\u0026#39;:numpy.array(result).tolist()}) if __name__ == \u0026#39;__main__\u0026#39;: app.run(host=\u0026#39;0.0.0.0\u0026#39;, port=8808, debug=True) 前端代码 此处偷懒了，都写到html里面了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1.0\u0026#34;\u0026gt; \u0026lt;title\u0026gt;让我康康\u0026lt;/title\u0026gt; \u0026lt;script type=\u0026#34;text/javascript\u0026#34; src=\u0026#34;https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;style\u0026gt; input { margin: 15px; } .myimg { max-height: 100vh; max-width: 100%; margin: auto; } .target-info { color: #f00; padding: 10px; border: solid 3px #f00; } table, th, td { border: 1px solid black; } \u0026lt;/style\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;h2\u0026gt;让我康康这有什么！\u0026lt;/h2\u0026gt; \u0026lt;p\u0026gt;支持拖拽图片到这行文字下方\u0026lt;/p\u0026gt; \u0026lt;div id=\u0026#34;dropBox\u0026#34; style=\u0026#34;min-height: 100px; min-height: 100px;\u0026#34;\u0026gt; \u0026lt;div id=\u0026#34;target\u0026#34; style=\u0026#34;position:absolute\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;img src=\u0026#34;\u0026#34; id=\u0026#34;myimg\u0026#34; class=\u0026#34;myimg\u0026#34;\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;input id=\u0026#34;fileInput\u0026#34; type=\u0026#34;file\u0026#34; onchange=\u0026#34;processFiles(this.files)\u0026#34;\u0026gt; \u0026lt;img id=\u0026#34;thumbnail\u0026#34;\u0026gt; \u0026lt;p id=\u0026#34;stat\u0026#34;\u0026gt;就绪\u0026lt;/p\u0026gt; \u0026lt;table id=\u0026#34;restab\u0026#34;\u0026gt; \u0026lt;tr\u0026gt;\u0026lt;th\u0026gt;Object\u0026lt;/th\u0026gt;\u0026lt;th\u0026gt;Confidence\u0026lt;/th\u0026gt;\u0026lt;/tr\u0026gt; \u0026lt;/table\u0026gt; \u0026lt;p\u0026gt;by xianfei 2021.12\u0026lt;/p\u0026gt; \u0026lt;script\u0026gt; var dropBox; window.onload = function () { dropBox = document.getElementById(\u0026#34;dropBox\u0026#34;); dropBox.ondragenter = ignoreDrag; dropBox.ondragover = ignoreDrag; dropBox.ondrop = drop; } function ignoreDrag(e) { //因为我们在处理拖放，所以应该确保没有其他元素会取得这个事件 e.stopPropagation(); e.preventDefault(); } function drop(e) { //取消事件传播及默认行为 e.stopPropagation(); e.preventDefault(); //取得拖进来的文件 var data = e.dataTransfer; var files = data.files; //将其传给真正的处理文件的函数 processFiles(files); } function ran() { return Math.floor(Math.random() * 256); } function processFiles(files) { $(\u0026#39;#stat\u0026#39;).html(\u0026#39;正在上传及处理中……\u0026#39;) var file = files[0]; const formData = new FormData(); formData.append(\u0026#39;file\u0026#39;, file) fetch(\u0026#34;/postimg\u0026#34;, { body: formData, method: \u0026#34;post\u0026#34; }).then(res =\u0026gt; { res.json().then(json =\u0026gt; { $(\u0026#39;#stat\u0026#39;).html(\u0026#39;检测到\u0026#39;+json.result.length+\u0026#39;个目标。\u0026#39;) var e = $(\u0026#39;#myimg\u0026#39;) var heightRate = e.height() / e[0].naturalHeight var widthRate = e.width() / e[0].naturalWidth if (json.result.length == 0) $(\u0026#39;#target\u0026#39;).append(\u0026#39;\u0026lt;div style=\u0026#34;position:absolute;width:100px;\u0026#34;\u0026gt;检测失败\u0026lt;/div\u0026gt;\u0026#39;) for (var i of json.result) { var color = \u0026#39;rgb(\u0026#39; + ran() + \u0026#39;,\u0026#39; + ran() + \u0026#39;,\u0026#39; + ran() + \u0026#39;)\u0026#39;; $(\u0026#39;#restab\u0026#39;).append(\u0026#39;\u0026lt;tr style=\u0026#34;color:\u0026#39; + color + \u0026#39;;\u0026#34;\u0026gt;\u0026lt;td\u0026gt;\u0026#39;+i[0]+\u0026#39;\u0026lt;/td\u0026gt;\u0026lt;td\u0026gt;\u0026#39;+i[2]+\u0026#39;\u0026lt;/td\u0026gt;\u0026lt;/tr\u0026gt;\u0026#39;) $(\u0026#39;#target\u0026#39;).append(\u0026#39;\u0026lt;div style=\u0026#34;position:absolute;margin-left:\u0026#39; + i[3] * widthRate + \u0026#39;px;margin-top:\u0026#39; + i[4] * heightRate + \u0026#39;px;width: \u0026#39; + (i[5] - i[3]) * widthRate + \u0026#39;px;height: \u0026#39; + (i[6] - i[4]) * heightRate + \u0026#39;px;border-color: \u0026#39; + color + \u0026#39;;color:\u0026#39; + color + \u0026#39;;\u0026#34; class=\u0026#34;target-info\u0026#34;\u0026gt;\u0026#39; + i[0] + \u0026#39;\u0026lt;/div\u0026gt;\u0026#39;) } console.log(json) }) }).catch(ex =\u0026gt; { consoleLog(\u0026#34;提交失败:\u0026#34; + ex.toString()); }); var output = document.getElementById(\u0026#34;fileOutput\u0026#34;); //创建FileReader var reader = new FileReader(); //告诉它在准备好数据之后做什么 reader.onload = function (e) { //使用图像URL来绘制dropBox的背景 $(\u0026#39;#myimg\u0026#39;)[0].src = e.target.result; $(\u0026#39;#target\u0026#39;).html(\u0026#39;\u0026#39;) $(\u0026#39;#restab\u0026#39;).html(\u0026#39;\u0026lt;tr\u0026gt;\u0026lt;th\u0026gt;Object\u0026lt;/th\u0026gt;\u0026lt;th\u0026gt;Confidence\u0026lt;/th\u0026gt;\u0026lt;/tr\u0026gt;\u0026#39;) }; //读取图片 reader.readAsDataURL(file); } function showFileInput() { var fileInput = document.getElementById(\u0026#34;fileInput\u0026#34;); fileInput.click(); } \u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; ","date":"2022-05-08T00:00:00Z","image":"/p/yolo/banner_hueca99897b332f16a3fd737e22c709ddd_1173106_120x120_fill_box_smart1_3.png","permalink":"/p/yolo/","title":"写一个简简单单的Python后端的Web目标识别网页吧"},{"content":"\n最近，冰墩墩火了！\n随着北京冬奥会开幕\n吉祥物“冰墩墩”一跃成为现象级顶流\n大家不禁纷纷直呼\n“谁不想要一只可爱的冰墩墩！”\n奥林匹克官方旗舰店冰墩墩周边一再售罄\n无论线上还是线下\n都实力演绎“一墩难求”\n技术背景 增强现实（Augmented Reality，简称AR），也有对应VR虚拟实境一词的翻译称为实拟虚境或扩张现实，是指透过摄影机影像的位置及角度精算并加上图像分析技术，让屏幕上的虚拟世界能够与现实世界场景进行结合与交互的技术。这种技术于1990年提出。随着随身电子产品运算能力的提升，增强现实的用途也越来越广。\n效果演示 使用方法 Android：需要一部支持ARCore并安装ARCore的手机 检查ARCore 对于ARCore的支持情况，可查看Google官方对于AR Core的文档（https://developers.google.com/ar/devices），如果自己的设备不支持且装有Magisk框架，可在Magisk中下载ARCore/Playground Patcher来强行支持\n对于MIUI等国产手机，需要在设置中启动Google基础服务，并去小米应用商店更新ARCore。对于默认装有Google服务的手机应该是自带的。\n需要Google应用或最新版的Chrome打开网页 网址：（建议翻墙进行） https://xianfei.github.io/ar2022/\n点击显示网页二维码 将该地址复制到Google应用或Chrome中即可。（iOS用户可以直接访问该链接） 推荐在Google应用中打开效果更好，视频中所展示的是通过系统自带浏览器（不支持WebXR）调用Google APP展示3D AR交互。请Play商店中下载Google应用，否则将会提示如下：\n或者使用Chrome等支持WebXR技术的浏览器进行打开，不过效果不如Google应用。WebXR是一项非常前沿的Web前端技术，浏览器们几乎很少支持\niOS: 直接在Safari中访问网站即可 https://xianfei.github.io/ar2022/\n点击显示网页二维码 点击立方体图标按钮进入AR模式 点击图中右下角的那个图标，即可进入AR模式。\n如果顺利的话，应该可以看见冰墩墩和雪容融了\n酷安头条 昨天凌晨睡觉前把它发到了酷安上，睡醒后发现上了头条，也有很多网友表示成功了，也有些网友提出了一些解决方案，没成功的读者可以在酷安评论区里看看有无有用的内容。\n此处为一些酷安网友在评论区晒的成功截图：\n技术方案 建模：Blender 展示：model-viewer\nAR展示技术可以参考Google ARCore WebXR 文档（ https://developers.google.com/ar/develop/webxr/model-viewer ）简单易懂，对前端开发稍有了解的同学肯定是一看就会。\n此处我们只需导出glb文件即可（如果想要在iOS中也能进行预览则需要导出usdz文件）在Blender完成3D建模后只需要导出glb和usdz文件即可（如果不会建模可以去b站搜一下许多up主分享了模型文件）值得注意的是，玻璃材质等涉及反射折射的材料在AR上不一定能实现，建议使用半透明的实色材质来绘制冰墩墩的外壳\n项目源代码：\nhttps://github.com/xianfei/xianfei.github.io/tree/master/static/ar2022\n","date":"2022-02-09T00:00:00Z","image":"/p/ar2022/ar2022_huf6485039128f9075441ee9cad5d655c0_500386_120x120_fill_box_smart1_3.png","permalink":"/p/ar2022/","title":"AR冰墩墩与雪容融！在家也能和冰墩墩合照啦~"},{"content":" 2021 年或许是平平淡淡的一年，又或许是充满挑战的一年。最近几天打算写一写自己的心得吧，或许也算是对去年的总结，又或是对未来的展望。文笔欠佳，见谅。\n首先来写写 2021 年吧，一转眼就大四了，大四的生活主要是在准备考研，考不考得上也不好说，就在今儿看空卡老师的公众号时看到了一调消息，觉得还挺好笑的。\n说道这里还有一个很好笑的：势态研凉\n好了，言归正传，让我来分享2021都经历了什么有趣的事情吧！\n2021.7 秦皇岛之旅——自驾游 2021的那个暑假，偶然提到了Aranya——秦皇岛的一个很文艺的社区，正好大家也想去海边了，以及想到了自驾游，于是我们就想到了这么一个安排！车还是那辆老车——老捷达，但是这个车别看虽然老，真的是好开，当时是晚上去的走的夜路，开了四个多小时吧开到了北戴河~\n这次出去玩我们订的是民宿，可以自己做饭，自己吃火锅。秦皇岛的物价很便宜，我们在那边有一家很喜欢的冰激凌店——碰碰凉，还有一家炸鸡店，可能是在北京生活习惯了，那边的这些东西物价还不到北京的一半儿而且量大！到了民宿，我们先要规划一下后几天的行程，对于我这样一个学软件工程专业的工科生，电脑当然是必不可少的了！我们第一天用电脑规划行程，后几天就是用电脑看电影了！\n我们决定第一天去Aranya，感受一下文艺气息，第二天去北戴河老虎石，第三天上午逛逛就准备回去了。当晚我们到那儿都很饿，于是就到了那附近的一家大排档撸串！你还别说他家的牛肉穿是真的好吃，比在北京吃的很多餐馆的都要好吃~\n吃完已经快凌晨一点了，于是我们决定——夜里看海！就像《藏起来》歌词“有人相爱，有人夜里开车看海”那样，我们把车开到了海边。这个地方白天是个景区，停车要钱，晚上也就没人管了。\n第二天来到Aranya，这真是一个十分文艺的小镇，建立在海边，可能大家所熟知的就是Aranya教堂了吧，这里借用小米同学的星轨。\n总的而言，在秦皇岛的旅途还是很开心的，也是我第一次自驾游。如果你对此感兴趣可以去看一下我的B站上的Vlog（https://www.bilibili.com/video/av504760418）\n2021.8 妙峰山野营 去秦皇岛是第一次自驾游的话，那么去妙峰山是我第一次自驾野营。其中有一个同学他对这方面很有经验，并且自己有帐篷什么的，我们还带了炭火和羊肉串、鱼豆腐、鸡翅等烧烤食材，可以在野外烧烤~\n同样这次活动也拍了vlog~如果感兴趣可以去看一下（https://www.bilibili.com/video/av717669473）\n2021.5 大创 北邮每年的大创展我都很喜欢，也是我每年必去的活动，在这里可以看到许多同学很有意思的想法，和他们交流技术，思维的碰撞之间或许能产生不一样的火花！\n2021.4 舞会 其实我是被叫来当摄影拍拍照的，平时在学校团委、青媒等学生组织当新闻摄影报道学校活动，而这次舞会不是官方活动所以我可以拍拍照顺便参与一下，感谢北邮舞协的朋友们教我如何跳舞！\n兴趣爱好——摄影 最早喜欢摄影是从高中开始，当时其实主要就是为了拍学校的一些活动（当时在学校电视台工作），之后大学也因为之前拍过不错的作品而在军训加入摄影宣传组（文体宣）而不用训练，在2021年也拍了许多自己满意的照片，还是像以前一样以人像摄影及校园活动为主。大家可以访问本站的摄影作品展（https://xianfei.ml:8001/gallery/）来观看哦~\n兴趣爱好——美食制作 俗话说得好，民以食为天，而好吃的食物，能使人在心情不好时感到治愈。其实我甚至向往以后的生活：开一个小饭馆，饭点儿做做菜迎接一些客人，而不是饭点儿的时候接一些外包项目写写代码赚一些小钱。感觉这样生活应该也不会太累也不会太穷。\n编程 我的专业是软件工程，所以编程应该也算是我的本行了，在暑假感谢于崔Sir的安排让我体验了一把打工人的生活，去工作了几天，帮忙完成一个小项目，用C++写一些大项目中涉及到的算法并进行测试，工资是每天一千块钱。这也算第一次去上班挣钱了吧~\n如果研究生没考上的话，之后也就是要去就业了，或者边工作边准备明年再考一年？不过无论到时候是不是在工作，还要保持学习的热情及对新知识的渴望。之前老师经常说，学会以后把所学的给其他人讲出来，会加深你对知识的理解，所以我决定在b站分享一些实用的编程技术。目前在做的是速成全栈工程师，做一个提问箱的系统，目前已经上传完第一集，第二集已经录完正在剪辑了，欢迎大家去看一下以及给个三连关注什么的！（https://www.bilibili.com/video/av808225151）\n人际交往 人际关系是困扰人类的永恒课题，人的烦恼绝大多数都是周围人带来的。人际交往的本质就是“社会认可战”，综合运用精神、物质、情感认可才是获胜的最佳策略。让你我都有良好的感觉，或者说是过得开心才是最重要的，俗话说得好“和气生财”，往往老板聊得来就可能会让你多多光顾一家店。最近看老梁讲的《如何练就令人拍案叫绝的现场反应》，讲的很是好，他还推出过情商课，这些在YouTube上能看到。我在本站搬运了一份，《如何练就令人拍案叫绝的现场反应》，讲的十分好，两个小时，强烈推荐大家能把他看完。（https://xianfei.ml:8001/?p=460，不支持iOS设备）\n2021-2022 元旦跨年 2022的元旦，和同学们到北京城里的胡同（东四那边）玩了玩，最近很喜欢许多奇奇怪怪而又没什么用的好玩的东西，生活嘛，应该充满仪式感。\n2022 2022，希望生活能够更好，希望开开心心，希望世界和平，希望考研上岸。\n年初去打卡了著名的地铁上岸站，正好芽芽同学就住在门头沟，顺便让她当个导游了，也祝她能考研上岸！\n突然想到明年就毕业了，希望疫情能够好转，能有一个更好的毕业旅行吧！如果有什么好的想法，欢迎在评论区留言！\n","date":"2022-01-27T00:00:00Z","image":"/p/my2021/clay-banks-HyczMwZbdLg-unsplash_hub4793d9bcd0c763f6c3c447eae921687_1203292_120x120_fill_q75_box_smart1.jpg","permalink":"/p/my2021/","title":"2021年度总结\u0026杂谈"},{"content":" 【释义】从目前的形势和状态分析，这次考研要凉。\n【例句】如今～，只好准备二战了。\n成语：\n释义： 从目前的形势和状态分析，这次考研要凉。 例句： 如今～，只好准备二战了。 本文是交互式Blog，请尝试改变上方输入框中的文字！\n","date":"2022-01-12T00:00:00Z","image":"/p/%E6%88%90%E8%AF%AD%E7%94%9F%E6%88%90%E5%99%A8/banner_huf1e48fbcfb498bd1e6f5485ca95ebe62_255681_120x120_fill_box_smart1_3.png","permalink":"/p/%E6%88%90%E8%AF%AD%E7%94%9F%E6%88%90%E5%99%A8/","title":"成语生成器"},{"content":"功能介绍 利用TCP/IP协议的局域网文件传输工具，通过ip地址及自定义的端口号进行连接。\n运行环境 通过测试的运行环境：macOS Mojave 10.14 \u0026amp; Fedora Linux Workstation 29\n依赖的软件包：dialog（图形库，需自己安装）、netcat(nc，用于对TCP/UDP进行读写，这两个系统自带)、net-tools（ifconfig，用于配置和显示Linux内核中网络接口，这两个系统自带）\nDialog安装方法：\nmacOS：使用brew包管理器安装。必要时请提供superuser权限。 在终端中输入以下命令\nbrew安装命令：（如果安装过请跳过这一步） /usr/bin/ruby -e \u0026quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)\u0026quot;\n使用brew包管理器安装命令： brew install dialog\nfedora: 使用yum包管理器安装。 在终端中输入以下命令\nsudo yum install dialog\n运行截图 源代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 #!/bin/bash send() { dialog --inputbox \u0026#34;请将文件拖到这里，或者输入绝对路径\u0026#34; 20 50 2\u0026gt; temp if [ $? != 0 ] then return 6 fi fileAddr=`cat temp` fileName=`echo ${fileAddr##*/}` dialog --inputbox \u0026#34;请输入您想使用的端口号\u0026#34; 20 50 2\u0026gt; temp if [ $? != 0 ] then return 6 fi sendPort=`cat temp` dialog --inputbox \u0026#34;请输入接收方的ip地址\u0026#34; 20 50 2\u0026gt; temp if [ $? != 0 ] then return 6 fi recvIP=`cat temp` dialog --title 正在发送 --infobox \u0026#34;正在发送文件$fileName \u0026#34; 20 50 echo $fileName | nc $recvIP $sendPort if [ $? != 0 ] then dialog --colors --msgbox \u0026#34;\\Z1 发送错误！请检查端口号及IP地址！\u0026#34; 0 0 return 6 fi sleep 1 nc $recvIP $sendPort \u0026lt; $fileAddr if [ $? != 0 ] then dialog --colors --msgbox \u0026#34;\\Z1 发送错误！\u0026#34; 0 0 return 6 fi fileSize=`ls -lh $fileAddr | awk \u0026#39;{print $5}\u0026#39;` dialog --msgbox \u0026#34;发送完成。\\n文件名：$fileName \\n大小：${fileSize}\u0026#34; 20 50 } recv() { dialog --inputbox \u0026#34;请输入您想使用的端口号\u0026#34; 20 50 2\u0026gt; temp if [ $? != 0 ] then return 6 fi recvPort=`cat temp` dialog --title \u0026#34;请选择接收路径\u0026#34; --fselect \u0026#34;${HOME}/\u0026#34; 8 50 2\u0026gt; temp if [ $? != 0 ] then return 6 fi recvAddr=`cat temp` localIP=`ifconfig | grep \u0026#34;inet\u0026#34; | awk \u0026#39;{ print $2}\u0026#39; | grep -v \u0026#34;127.0.0.1\u0026#34; | grep -v \u0026#34;:\u0026#34;` dialog --title 等待接受 --infobox \u0026#34;本机IP：$localIP \\n端口号：$recvPort\u0026#34; 20 50 nc -l $recvPort \u0026gt; temp if [ $? != 0 ] then dialog --colors --msgbox \u0026#34;\\Z1 接收错误！\u0026#34; 0 0 return 6 fi recvFile=`cat temp` dialog --infobox \u0026#34;正在接收文件 $recvFile ……\u0026#34; 20 50 nc -l $recvPort \u0026gt; filetemp if [ $? != 0 ] then dialog --colors --msgbox \u0026#34;\\Z1 接收错误！\u0026#34; 0 0 return 6 fi mv filetemp ${recvAddr}/${recvFile} fileSize=`ls -lh ${recvAddr}/${recvFile} | awk \u0026#39;{print $5}\u0026#39;` dialog --msgbox \u0026#34;接收完成。\\n文件名：$recvFile \\n大小：${fileSize}\u0026#34; 20 50 } mainUI() { dialog --cancel-label 退出 --title Shell文件传输助手 --menu \u0026#34; \\n \u0026#34; 20 50 8 1 \u0026#34;发送文件\u0026#34; 2 \u0026#34;接收文件\u0026#34; 3 \u0026#34;关于\u0026#34; 4 \u0026#34;退出\u0026#34; 2\u0026gt; temp a1=`cat temp` case $a1 in 1) send if [ $? = 6 ] then mainUI fi ;; 2) recv if [ $? = 6 ] then mainUI fi ;; 3) dialog --colors --msgbox \u0026#34;Shell文件传输助手 \\n\\nBeta Version 2019.3.5\\n\\n\\Z6开发人员：\\n王衔飞 李思涵 胡嘉慧 丁玲\u0026#34; 20 50 mainUI ;; 4) return ;; esac } mainUI clear rm -f temp rm -f filetemp ","date":"2019-03-05T00:00:00Z","image":"/p/shell-file-trans/1_huf95364caf60a3b9d7580a3cfd70ebe86_78402_120x120_fill_q75_h2_box_smart1_2.webp","permalink":"/p/shell-file-trans/","title":"Shell File Transfer —— 适用于Linux/macOS的局域网文件传输程序"},{"content":"前言 一个基于C语言的多平台控制台扫雷软件，可以实现Windows系统自带小游戏扫雷的所有功能。实现了自定义游戏参数、第一次不会踩到雷、挖雷、标记、自动处理无雷区域、一定条件下快速挖开周围区域的功能。控制台版本使用操作命令+行列坐标方式实现。\n流程图 源代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;string.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;time.h\u0026gt; //设定为挖开和已标记填充的字符 #define undigged \u0026#34;▣\u0026#34; #define marked \u0026#34;∅\u0026#34; //行列数及雷数 unsigned int row = 16; unsigned int col = 30; unsigned int minenum = 9; //随机造雷函数 int makemine(int mine[32][32]) { int a[minenum]; //用于保存雷的位置 int i, j; for (i = 1; i \u0026lt; row + 1; i++) { for (j = 1; j \u0026lt; col + 1; j++) { mine[i][j] = 0;//遍历清空 用于第一次踩到雷重新造雷用 } } srand((int) time(0)); a[0] = rand() % (row * col); for (i = 1; i \u0026lt; minenum; i++) { a[i] = rand() % (row * col); for (j = 0; j \u0026lt; i; j++) { if (a[i] == a[j]) i--; } } for (i = 0; i \u0026lt; minenum; i++) { //将前面产生的雷的位置写入到数组中 int x = a[i] / col + 1; int y = a[i] % col + 1; mine[x][y] = 1; } return 0; } //输出雷盘 int output(char show[31][31][4]) { int i, j; for (i = 1; i \u0026lt; row + 1; i++) { printf(\u0026#34;%3d \u0026#34;, i); for (j = 1; j \u0026lt; col + 1; j++) { printf(\u0026#34;%s \u0026#34;, show[i][j]); } putchar(\u0026#39;\\n\u0026#39;); } return 0; } //计算x,y周围的雷数 int scanmine(int mine[32][32], int x, int y) { int n = 0, i, j; for (i = 1; i \u0026gt; -2; i--) { for (j = 1; j \u0026gt; -2; j--) { if (mine[x + i][y + j] == 1)n++; } } return n; } //用于自动打开没有雷的区域 void chuli0(char show[31][31][4], int mine[32][32]) { int x, y, i, j; for (x = 1; x \u0026lt; row + 1; x++) { for (y = 1; y \u0026lt; col + 1; y++) { if (show[x][y][0] == \u0026#39; \u0026#39;) { for (i = 1; i \u0026gt; -2; i--) { for (j = 1; j \u0026gt; -2; j--) { if (scanmine(mine, x + i, y + j)) show[x + i][y + j][0] = \u0026#39;0\u0026#39; + scanmine(mine, x + i, y + j); else show[x + i][y + j][0] = \u0026#39; \u0026#39;; show[x + i][y + j][1] = 0; } } } } } } //计算剩余未挖开地方的数 int least(char show[31][31][4]) { int i, j, n = 0; for (i = 1; i \u0026lt; row + 1; i++) { for (j = 1; j \u0026lt; col + 1; j++) { if (!(strcmp(show[i][j], undigged)))n++; if (!(strcmp(show[i][j], marked)))n++; } } return n; } //执行游戏 int game(char show[31][31][4], int mine[32][32],int flag[31][31]){ while(getchar() != \u0026#39;\\n\u0026#39;);//清除键盘缓冲区 int i = 0, j = 0, k = 0, x, y; static int flagnum = 0; printf(\u0026#34;未挖开：%d \u0026#34;, least(show)); printf(\u0026#34;剩余雷：%d \u0026#34;, minenum - flagnum); printf(\u0026#34;已标记：%d\\n\u0026#34;, flagnum); printf(\u0026#34; \u0026#34;); for (i = 0; i \u0026lt; col; i++)printf(\u0026#34;%c \u0026#34;, i + \u0026#39;a\u0026#39;); putchar(\u0026#39;\\n\u0026#39;); output(show); puts(\u0026#34;\\n请输入操作和列号行号:(操作：d挖开,f标记/取消标记,o尝试打开四周)\u0026#34;); int opt = getchar(); y = getchar() - \u0026#39;a\u0026#39; + 1; scanf(\u0026#34;%d\u0026#34;, \u0026amp;x); //printf(\u0026#34;%d--%d\u0026#34;,x,y); if(x\u0026lt;1||x\u0026gt;row||y\u0026lt;1||y\u0026gt;row){ puts(\u0026#34;error\u0026#34;); puts(\u0026#34;\\n\\n\\n\u0026#34;); return 1;//查错语句 } switch (opt) { case \u0026#39;d\u0026#39;: if (flag[x][y]) { puts(\u0026#34;\\n\\n\u0026#34;); printf(\u0026#34;该处已被标记，请取消后重试！！！\u0026#34;); puts(\u0026#34;\\n\u0026#34;); break; } else { if (mine[x][y] \u0026amp;\u0026amp; (least(show) != col * row)) { printf(\u0026#34;你炸了！！！\u0026#34;); return 0; } if (mine[x][y] \u0026amp;\u0026amp; (least(show) == col * row)) { do { makemine(mine); }//防止第一次踩到雷 while (mine[x][y]); } if (!mine[x][y]) { if (scanmine(mine, x, y)) show[x][y][0] = \u0026#39;0\u0026#39; + scanmine(mine, x, y); else show[x][y][0] = \u0026#39; \u0026#39;; show[x][y][1] = 0; if (!(scanmine(mine, x, y))) { for (k = 0; k \u0026lt; (col \u0026gt; row ? col : row); k++)chuli0(show, mine); } puts(\u0026#34;\\n\\n\\n\u0026#34;); break; } } case \u0026#39;f\u0026#39;: flag[x][y] = !flag[x][y]; if (flag[x][y]) { strcpy(show[x][y], marked); flagnum++; } else { strcpy(show[x][y], undigged); flagnum--; } puts(\u0026#34;\\n\\n\\n\u0026#34;); break; case \u0026#39;o\u0026#39;: k = 0; for (i = 1; i \u0026gt; -2; i--) { for (j = 1; j \u0026gt; -2; j--) { if (!(strcmp(show[x + i][y + j], marked)))k++; } } if (k != scanmine(mine, x, y)) { puts(\u0026#34;\\n\\n\u0026#34;); puts(\u0026#34;无法快速打开，周围未全部标记\u0026#34;); puts(\u0026#34;\\n\u0026#34;); break; } for (i = 1; i \u0026gt; -2; i--) { for (j = 1; j \u0026gt; -2; j--) { if (!(strcmp(show[x + i][y + j], undigged))) { if (scanmine(mine, x + i, y + j)) show[x + i][y + j][0] = \u0026#39;0\u0026#39; + scanmine(mine, x + i, y + j); else show[x + i][y + j][0] = \u0026#39; \u0026#39;; show[x + i][y + j][1] = 0; if (!(scanmine(mine, x + i, y + j))) { for (k = 0; k \u0026lt; (col \u0026gt; row ? col : row); k++)chuli0(show, mine); } } } } puts(\u0026#34;\\n\\n\\n\u0026#34;); break; default: puts(\u0026#34;error\u0026#34;); puts(\u0026#34;\\n\\n\\n\u0026#34;); } if (least(show) == minenum) { printf(\u0026#34;你赢了！！！\u0026#34;); return 0; } return 1; } //选择难度 int choose(){ puts(\u0026#34;请选择难度：\u0026#34;); puts(\u0026#34;1.初级 9x9 10个雷\u0026#34;); puts(\u0026#34;2.中级 16x16 40个雷\u0026#34;); puts(\u0026#34;3.高级 16x30 99个雷\u0026#34;); puts(\u0026#34;4.自定义\u0026#34;); printf(\u0026#34;请输入序号：\u0026#34;); switch (getchar()) { case \u0026#39;1\u0026#39;: minenum = 10; row = 9; col = 9; break; case \u0026#39;2\u0026#39;: minenum = 40; row = 16; col = 16; break; case \u0026#39;3\u0026#39;: minenum = 99; row = 16; col = 30; break; case \u0026#39;4\u0026#39;: puts(\u0026#34;请输入行数：\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;row); puts(\u0026#34;请输入列数：\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;col); puts(\u0026#34;请输入雷数：\u0026#34;); scanf(\u0026#34;%d\u0026#34;, \u0026amp;minenum); if (row \u0026gt; 24 || col \u0026gt; 30 || minenum \u0026gt; 0.9 * col * row) { puts(\u0026#34;行数不能大于24，列数不能大于30\u0026#34;); puts(\u0026#34;雷数不能大于方格数的90%\u0026#34;); while(getchar() != \u0026#39;\\n\u0026#39;);//清除键盘缓冲区 return 1; } break; default: puts(\u0026#34;error\u0026#34;); while(getchar() != \u0026#39;\\n\u0026#39;);//清除键盘缓冲区 return 1; } return 0; } int main() { while(choose());//选择游戏难度，如果正确选择返回值应为0 int mine[32][32] = {0}, flag[31][31] = {0},i,j; makemine(mine);//造雷 putchar(\u0026#39;\\n\u0026#39;); char show[30 + 1][30 + 1][4] = {0};//用于储存雷盘显示的字符串 在macos/linux上特殊符号占用3byte for (i = 1; i \u0026lt; row + 1; i++) { for (j = 1; j \u0026lt; col + 1; j++) { strcpy(show[i][j], undigged);//初始化雷盘 } } while (game(show,mine,flag));//执行游戏 游戏结束时返回值应为0 return 0; } ","date":"2019-01-11T00:00:00Z","image":"/p/minesweeper-cli/cta_hu5d6229566403b571e354b7e8d7d45994_52875_120x120_fill_box_smart1_3.png","permalink":"/p/minesweeper-cli/","title":"扫雷 Command Line Version with C"},{"content":"（从老的博客系统迁移而来，查看原始文章）\n1. 个人简介 北京邮电大学软件学院软件工程系王衔飞。\nArduino开发吧，兴趣还是很重要的，Arduino是个很好玩的东西，不仅能学习编程本领，也可以用于模拟电路实践。大家要利用好手中的Arduino，能实现许许多多的有意思的功能哦。\nThe only limit is your imagination. 要敢想敢做，课上的代码只是用作参考，用Arduino还能实现更多的东西，例如可以用温度计和继电器，让温度过高时自动打开电风扇；将该电子时钟中的闹钟蜂鸣器改成继电器，实现定时开关电器；利用Arduino模拟输入做电压表；利用Arduino的PWM管脚做遥控调光等等……\n2. 实验简介 2.0 实验材料 ArduinoUno开发板及扩展版，屏幕模块，IR接收模块，遥控器，蜂鸣器，（v2新增）温湿度传感器。\n2.1 程序功能 一个小小的时钟程序，具有显示及修改时间日期星期、设定闹钟功能。在v2版本中加入了温度显示、切换24小时制等功能。\n2.2 程序设计 电源键：返回主界面\n1键：修改时间\n2键：设定闹钟\n3键：修改日期\n4键：取消闹钟\nv2版本增加：\n5键：切换24小时制\n6键：显示温度\n7键：切换背光开关\n2.3 程序及代码亮点 美观的UI及更加人性化的提示 直接使用遥控器进行输入数字，更加方便快捷 可在代码顶部进行自定义设定 模块化代码，使用recv（接收遥控信号）、remote（处理遥控信号）、gettime（获取时间日期及时间流动）、output（输出主屏幕）、alarmrun（闹钟响铃）函数组成，提高代码易读性。 3. 视频介绍 修改时间演示视频\n修改日期演示视频\n设定闹钟及闹钟响起演示视频\n切换24小时制演示视频\n切换是否显示温度演示视频\n切换背光开关演示视频\n4. 附件 v2 源代码下载：clock_wxf_v2.zip (5.81KB)\nv1.1 源代码下载：arduino_clock_by_xianfei.zip (5.35KB)\n更新日志： V2：2018.12.25\n加入温度计、24小时制切换、开关屏幕背光功能，优化代码易读性及使用宏定义更加方便对代码进行个性化调整。\nV1.1：2018.11.23\n优化时序逻辑降低接收信号延时，优化算法提高接收信号成功率，优化系统稳定性并降低内存占用提高执行效率。\nV1.0：2018.10.31\n完成第一版，具备闹钟、修改时间日期、显示时间日期功能。使用直接输入的方式输入时间日期及设定闹钟。\n","date":"2018-12-25T00:00:00Z","image":"/p/rgdl/banner_hucbf45743131c576b95ad4a52763c8559_144779_120x120_fill_q75_box_smart1.jpg","permalink":"/p/rgdl/","title":"Arduino小实验——大一软件工程专业导论实践课"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution Tiam, ad mint andaepu dandae nostion secatur sequo quae. Note that you can use Markdown syntax within a blockquote.\nBlockquote with attribution Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\nTables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\nName Age Bob 27 Alice 23 Inline Markdown within tables Italics Bold Code italics bold code A B C D E F Lorem ipsum dolor sit amet, consectetur adipiscing elit. Phasellus ultricies, sapien non euismod aliquam, dui ligula tincidunt odio, at accumsan nulla sapien eget ex. Proin eleifend dictum ipsum, non euismod ipsum pulvinar et. Vivamus sollicitudin, quam in pulvinar aliquam, metus elit pretium purus Proin sit amet velit nec enim imperdiet vehicula. Ut bibendum vestibulum quam, eu egestas turpis gravida nec Sed scelerisque nec turpis vel viverra. Vivamus vitae pretium sapien Code Blocks Code block with backticks 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;utf-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10 \u0026lt;!doctype html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Diff code block 1 2 3 4 5 [dependencies.bevy] git = \u0026#34;https://github.com/bevyengine/bevy\u0026#34; rev = \u0026#34;11f52b8c72fc3a568e8bb4a4cd1f3eb025ac2e13\u0026#34; - features = [\u0026#34;dynamic\u0026#34;] + features = [\u0026#34;jpeg\u0026#34;, \u0026#34;dynamic\u0026#34;] List Types Ordered List First item Second item Third item Unordered List List item Another item And another item Nested list Fruit Apple Orange Banana Dairy Milk Cheese Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn = Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\nHyperlinked image The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2000-03-11T00:00:00Z","image":"/p/markdown-%E8%AF%AD%E6%B3%95%E6%8C%87%E5%8D%97/pawel-czerwinski-8uZPynIu-rQ-unsplash_hud7e36f7e20e71be184458283bdae4646_55974_120x120_fill_q75_box_smart1.jpg","permalink":"/p/markdown-%E8%AF%AD%E6%B3%95%E6%8C%87%E5%8D%97/","title":"Markdown 语法指南"}]